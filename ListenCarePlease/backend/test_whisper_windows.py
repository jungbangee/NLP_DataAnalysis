"""
Windowsì—ì„œ Whisper ë©”ëª¨ë¦¬ ì—ëŸ¬ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
1. ê°€ìƒí™˜ê²½ í™œì„±í™” (conda ë˜ëŠ” venv)
2. python test_whisper_windows.py

í…ŒìŠ¤íŠ¸ í•­ëª©:
- ë¡œì»¬ Whisper ëª¨ë¸ ë¡œë”© (tiny, base, small)
- ì§§ì€ ì˜¤ë””ì˜¤ íŒŒì¼ ì „ì‚¬
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
"""

import os
import sys
import psutil
import time
from pathlib import Path

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶œë ¥
def print_memory_usage():
    process = psutil.Process()
    mem_info = process.memory_info()
    mem_mb = mem_info.rss / 1024 / 1024
    print(f"ğŸ’¾ í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {mem_mb:.1f} MB")
    return mem_mb


def test_whisper_import():
    """Whisper ë¼ì´ë¸ŒëŸ¬ë¦¬ import í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*60)
    print("TEST 1: Whisper ë¼ì´ë¸ŒëŸ¬ë¦¬ import")
    print("="*60)

    try:
        import whisper
        print("âœ… openai-whisper ì„¤ì¹˜ë¨")
        print(f"   ë²„ì „: {whisper.__version__}")
        return True
    except ImportError as e:
        print("âŒ openai-whisper ì„¤ì¹˜ ì•ˆë¨")
        print(f"   ì—ëŸ¬: {e}")
        print("\nì„¤ì¹˜ ë°©ë²•:")
        print("  pip install openai-whisper")
        return False


def test_model_loading(model_sizes=["tiny", "base"]):
    """ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*60)
    print("TEST 2: Whisper ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸")
    print("="*60)

    try:
        import whisper
        import torch
    except ImportError:
        print("âŒ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return False

    print(f"ğŸ–¥ï¸  ë””ë°”ì´ìŠ¤: CPU")
    print(f"ğŸ”¢ Torch ë²„ì „: {torch.__version__}")
    print_memory_usage()

    results = {}

    for model_size in model_sizes:
        print(f"\n{'â”€'*60}")
        print(f"ëª¨ë¸: {model_size}")
        print(f"{'â”€'*60}")

        try:
            print(f"ğŸ“¥ {model_size} ëª¨ë¸ ë¡œë”© ì¤‘...")
            start_time = time.time()
            start_mem = print_memory_usage()

            model = whisper.load_model(model_size, device="cpu")

            elapsed = time.time() - start_time
            end_mem = print_memory_usage()
            mem_increase = end_mem - start_mem

            print(f"âœ… ë¡œë”© ì™„ë£Œ")
            print(f"   ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ")
            print(f"   ë©”ëª¨ë¦¬ ì¦ê°€: +{mem_increase:.1f} MB")

            results[model_size] = {
                "success": True,
                "time": elapsed,
                "memory": mem_increase
            }

            # ë©”ëª¨ë¦¬ í•´ì œ
            del model
            import gc
            gc.collect()

            time.sleep(1)

        except Exception as e:
            print(f"âŒ ë¡œë”© ì‹¤íŒ¨")
            print(f"   ì—ëŸ¬: {e}")
            results[model_size] = {
                "success": False,
                "error": str(e)
            }

    # ê²°ê³¼ ìš”ì•½
    print("\n" + "="*60)
    print("ğŸ“Š ëª¨ë¸ ë¡œë”© ê²°ê³¼ ìš”ì•½")
    print("="*60)
    for model_size, result in results.items():
        if result["success"]:
            print(f"âœ… {model_size:10s}: {result['time']:5.1f}ì´ˆ, {result['memory']:6.1f} MB")
        else:
            print(f"âŒ {model_size:10s}: {result['error']}")

    return results


def test_transcription():
    """ì‹¤ì œ ì „ì‚¬ í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*60)
    print("TEST 3: ì˜¤ë””ì˜¤ ì „ì‚¬ í…ŒìŠ¤íŠ¸")
    print("="*60)

    # í…ŒìŠ¤íŠ¸ ì˜¤ë””ì˜¤ íŒŒì¼ í™•ì¸
    test_audio = Path("test_audio.wav")
    if not test_audio.exists():
        print("âš ï¸  í…ŒìŠ¤íŠ¸ ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("   test_audio.wav íŒŒì¼ì„ ì¤€ë¹„í•˜ê³  ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")
        return False

    try:
        import whisper
    except ImportError:
        print("âŒ openai-whisperê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return False

    print(f"ğŸµ í…ŒìŠ¤íŠ¸ íŒŒì¼: {test_audio}")
    print_memory_usage()

    try:
        print("\nğŸ“¥ tiny ëª¨ë¸ ë¡œë”©...")
        model = whisper.load_model("tiny", device="cpu")
        print_memory_usage()

        print("\nâ–¶ï¸  ì „ì‚¬ ì‹œì‘...")
        start_time = time.time()

        result = model.transcribe(
            str(test_audio),
            language="ko",
            verbose=False
        )

        elapsed = time.time() - start_time
        print(f"âœ… ì „ì‚¬ ì™„ë£Œ ({elapsed:.1f}ì´ˆ)")
        print_memory_usage()

        print("\nğŸ“ ì „ì‚¬ ê²°ê³¼:")
        print(f"   {result['text']}")

        return True

    except Exception as e:
        print(f"âŒ ì „ì‚¬ ì‹¤íŒ¨")
        print(f"   ì—ëŸ¬: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_memory_limit():
    """ë©”ëª¨ë¦¬ ì œí•œ í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*60)
    print("TEST 4: ë©”ëª¨ë¦¬ ì œí•œ í™•ì¸")
    print("="*60)

    process = psutil.Process()
    mem_info = process.memory_info()

    # ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ì •ë³´
    virtual_mem = psutil.virtual_memory()

    print(f"ğŸ’¾ ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬:")
    print(f"   ì´ ë©”ëª¨ë¦¬: {virtual_mem.total / 1024 / 1024 / 1024:.1f} GB")
    print(f"   ì‚¬ìš© ê°€ëŠ¥: {virtual_mem.available / 1024 / 1024 / 1024:.1f} GB")
    print(f"   ì‚¬ìš©ë¥ : {virtual_mem.percent}%")

    print(f"\nğŸ’¾ í˜„ì¬ í”„ë¡œì„¸ìŠ¤:")
    print(f"   ë©”ëª¨ë¦¬ ì‚¬ìš©: {mem_info.rss / 1024 / 1024:.1f} MB")

    # ê¶Œì¥ ëª¨ë¸ í¬ê¸°
    available_gb = virtual_mem.available / 1024 / 1024 / 1024

    print(f"\nğŸ’¡ ê¶Œì¥ ëª¨ë¸:")
    if available_gb < 2:
        print(f"   âš ï¸  ì‚¬ìš© ê°€ëŠ¥ ë©”ëª¨ë¦¬ ë¶€ì¡± ({available_gb:.1f} GB)")
        print(f"   ê¶Œì¥: tiny ë˜ëŠ” base ëª¨ë¸")
    elif available_gb < 4:
        print(f"   tiny, base, small ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥")
    elif available_gb < 8:
        print(f"   tiny ~ medium ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥")
    else:
        print(f"   ëª¨ë“  ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥")


def main():
    print("="*60)
    print("ğŸªŸ Windows Whisper ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸")
    print("="*60)

    # í”Œë«í¼ í™•ì¸
    print(f"\nğŸ–¥ï¸  ìš´ì˜ì²´ì œ: {sys.platform}")
    print(f"ğŸ Python ë²„ì „: {sys.version}")

    # TEST 1: Import
    if not test_whisper_import():
        print("\nâŒ Whisperê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ ì¤‘ë‹¨.")
        return

    # TEST 2: ëª¨ë¸ ë¡œë”©
    test_model_loading(["tiny", "base"])

    # TEST 3: ì „ì‚¬ (ì„ íƒì )
    # test_transcription()

    # TEST 4: ë©”ëª¨ë¦¬ í™•ì¸
    test_memory_limit()

    # ìµœì¢… ê¶Œì¥ì‚¬í•­
    print("\n" + "="*60)
    print("ğŸ“Œ ê¶Œì¥ì‚¬í•­")
    print("="*60)
    print("1. ë©”ëª¨ë¦¬ ì—ëŸ¬ê°€ ë°œìƒí•˜ë©´ ì‘ì€ ëª¨ë¸ ì‚¬ìš©:")
    print("   - WHISPER_MODEL_SIZE=tiny")
    print("   - WHISPER_MODEL_SIZE=base")
    print("")
    print("2. .env íŒŒì¼ì—ì„œ ì„¤ì • ë³€ê²½:")
    print("   WHISPER_MODE=local")
    print("   WHISPER_MODEL_SIZE=base")
    print("   WHISPER_DEVICE=cpu")
    print("")
    print("3. ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ API ì‚¬ìš©:")
    print("   WHISPER_MODE=api")
    print("   OPENAI_API_KEY=your-api-key")


if __name__ == "__main__":
    main()
