from fastapi import APIRouter, HTTPException, Depends, BackgroundTasks
from sqlalchemy.orm import Session
from sqlalchemy import func
from app.api.deps import get_db
from langsmith import traceable
from app.models.audio_file import AudioFile
from app.models.tagging import DetectedName, SpeakerMapping
from app.models.user_confirmation import UserConfirmation
from app.models.stt import STTResult
from app.models.diarization import DiarizationResult
from app.services.agent_data_loader import load_agent_input_data_by_file_id
from app.agents.graph import get_speaker_tagging_app
from app.schemas.tagging import (
    TaggingSuggestionDetailResponse,
    SuggestedMapping,
    TranscriptSegment,
    TaggingConfirmRequest,
    TaggingConfirmResponse,
    SpeakerInfoConfirmRequest
)

router = APIRouter()

# Mock ë°ì´í„° ì €ì¥ì†Œ (ì¼ë¶€ ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ê³„ì† ì‚¬ìš©)
TAGGING_RESULTS = {}
SPEAKER_INFO = {}  # í™”ì ì •ë³´ í™•ì¸ í˜ì´ì§€ì—ì„œ ì €ì¥í•œ ë°ì´í„°


@router.get("/speaker-info/{file_id}")
async def get_speaker_info(file_id: str, db: Session = Depends(get_db)):
    """
    í™”ì ì •ë³´ ì¡°íšŒ - í™”ì ìˆ˜ + ê°ì§€ëœ ì´ë¦„
    í”„ë¡œì„¸ì‹± ì™„ë£Œ í›„ ì‚¬ìš©ì í™•ì¸ì„ ìœ„í•œ ê¸°ë³¸ ì •ë³´ ì œê³µ
    """
    # DBì—ì„œ audio_file ì°¾ê¸°
    audio_file = db.query(AudioFile).filter(
        (AudioFile.file_path.like(f"%{file_id}%")) |
        (AudioFile.original_filename.like(f"%{file_id}%"))
    ).first()

    if not audio_file:
        raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    # í™”ì ìˆ˜ ì¡°íšŒ (SpeakerMappingì—ì„œ ê³ ìœ  í™”ì ë ˆì´ë¸” ê°œìˆ˜)
    speaker_count = db.query(func.count(SpeakerMapping.id)).filter(
        SpeakerMapping.audio_file_id == audio_file.id
    ).scalar() or 0

    # ê°ì§€ëœ ì´ë¦„ ì¡°íšŒ (DetectedNameì—ì„œ ì¤‘ë³µ ì œê±°í•œ ì´ë¦„ ë¦¬ìŠ¤íŠ¸)
    detected_names_query = db.query(DetectedName.detected_name).filter(
        DetectedName.audio_file_id == audio_file.id
    ).distinct().all()

    detected_names = [name[0] for name in detected_names_query]

    # ë‹‰ë„¤ì„ ì¡°íšŒ (í™”ìë³„ ë‹‰ë„¤ì„)
    speaker_mappings = db.query(SpeakerMapping).filter(
        SpeakerMapping.audio_file_id == audio_file.id
    ).all()
    detected_nicknames = []
    for mapping in speaker_mappings:
        if mapping.nickname:
            detected_nicknames.append(mapping.nickname)

    return {
        "file_id": file_id,
        "speaker_count": speaker_count,
        "detected_names": detected_names,
        "detected_nicknames": detected_nicknames,  # ë‹‰ë„¤ì„ ì¶”ê°€
        "processing_status": audio_file.status.value if audio_file.status else "unknown"
    }


@router.post("/speaker-info/confirm")
async def confirm_speaker_info(
    request: SpeakerInfoConfirmRequest, 
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db)
):
    """
    í™”ì ì •ë³´ í™•ì • - ì‚¬ìš©ìê°€ ìˆ˜ì •í•œ í™”ì ìˆ˜ ë° ì´ë¦„ ì €ì¥
    """
    try:
        file_id = request.file_id
        speaker_count = request.speaker_count
        detected_names = request.detected_names
        detected_nicknames = request.detected_nicknames or []

        print(f"ğŸ” í™”ì ì •ë³´ í™•ì • ìš”ì²­: file_id={file_id}, speaker_count={speaker_count}, detected_names={detected_names}, detected_nicknames={detected_nicknames}")

        # DBì—ì„œ audio_file ì°¾ê¸°
        audio_file = db.query(AudioFile).filter(
            (AudioFile.file_path.like(f"%{file_id}%")) |
            (AudioFile.original_filename.like(f"%{file_id}%"))
        ).first()

        if not audio_file:
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: file_id={file_id}")
            raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        print(f"âœ… AudioFile ì°¾ìŒ: id={audio_file.id}, file_path={audio_file.file_path}")

        # ê¸°ì¡´ UserConfirmationì´ ìˆëŠ”ì§€ í™•ì¸ (ì—…ë°ì´íŠ¸ vs ìƒì„±)
        existing_confirmation = db.query(UserConfirmation).filter(
            UserConfirmation.audio_file_id == audio_file.id
        ).first()

        if existing_confirmation:
            # ì—…ë°ì´íŠ¸
            print(f"ğŸ”„ ê¸°ì¡´ UserConfirmation ì—…ë°ì´íŠ¸: id={existing_confirmation.id}")
            existing_confirmation.confirmed_speaker_count = speaker_count
            existing_confirmation.confirmed_names = detected_names
            existing_confirmation.confirmed_nicknames = detected_nicknames
        else:
            # ìƒˆë¡œ ìƒì„±
            print(f"â• ìƒˆ UserConfirmation ìƒì„±: audio_file_id={audio_file.id}")
            user_confirmation = UserConfirmation(
                audio_file_id=audio_file.id,
                confirmed_speaker_count=speaker_count,
                confirmed_names=detected_names,
                confirmed_nicknames=detected_nicknames
            )
            db.add(user_confirmation)

        db.commit()
        print(f"âœ… í™”ì ì •ë³´ ì €ì¥ ì™„ë£Œ: audio_file_id={audio_file.id}")

        # í™”ì ìˆ˜ê°€ ë³€ê²½ë˜ì—ˆê±°ë‚˜, ê¸°ì¡´ì— í™•ì •ëœ ì ì´ ì—†ë‹¤ë©´ ì¬ë¶„ì„ íŠ¸ë¦¬ê±°
        should_reprocess = False
        if existing_confirmation:
            if existing_confirmation.confirmed_speaker_count != speaker_count:
                should_reprocess = True
                print(f"ğŸ”„ í™”ì ìˆ˜ ë³€ê²½ ê°ì§€: {existing_confirmation.confirmed_speaker_count} -> {speaker_count}")
        else:
            # ì²˜ìŒ í™•ì •í•˜ëŠ” ê²½ìš°ì—ë„ ì¬ë¶„ì„ (í™•ì‹¤í•˜ê²Œ í•˜ê¸° ìœ„í•´)
            should_reprocess = True
            print(f"ğŸ”„ í™”ì ìˆ˜ ìµœì´ˆ í™•ì •: {speaker_count}ëª…")

        if should_reprocess:
            from app.api.v1.processing import process_audio_pipeline, PROCESSING_STATUS
            from app.models.audio_file import FileStatus
            
            # ìƒíƒœ ì´ˆê¸°í™”
            audio_file.status = FileStatus.PROCESSING
            audio_file.processing_step = "preprocessing"
            audio_file.processing_progress = 0
            audio_file.processing_message = f"ì¬ë¶„ì„ ì¤‘ (í™”ì ìˆ˜: {speaker_count}ëª…, STT ê±´ë„ˆëœ€)..."
            db.commit()
            
            # ë©”ëª¨ë¦¬ ìƒíƒœ ì´ˆê¸°í™”
            PROCESSING_STATUS[file_id] = {
                "status": "queued",
                "step": f"ì¬ë¶„ì„ ëŒ€ê¸° ì¤‘ (í™”ì ìˆ˜: {speaker_count}ëª…)...",
                "progress": 0
            }
            
            # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ì¶”ê°€ (STT ê±´ë„ˆë›°ê³  Diarizationë¶€í„° ë‹¤ì‹œ ì‹¤í–‰)
            background_tasks.add_task(
                process_audio_pipeline,
                file_id=file_id,
                user_id=audio_file.user_id, # Pass user_id
                whisper_mode="local", # ê¸°ë³¸ê°’ ì‚¬ìš©
                diarization_mode="nemo", # NeMo ê°•ì œ (í™”ì ìˆ˜ ì§€ì •ì€ NeMoë§Œ ì§€ì›)
                skip_stt=True # STT ê±´ë„ˆë›°ê¸°
            )
            
            return {
                "message": f"í™”ì ì •ë³´ê°€ ì €ì¥ë˜ì—ˆìœ¼ë©°, {speaker_count}ëª…ìœ¼ë¡œ ì¬ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤. (STT ìƒëµ)",
                "status": "reprocessing_started"
            }

        return {
            "message": "í™”ì ì •ë³´ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "status": "success"
        }
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ í™”ì ì •ë³´ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {type(e).__name__}: {str(e)}")
        import traceback
        traceback.print_exc()
        db.rollback()
        raise HTTPException(
            status_code=500,
            detail=f"í™”ì ì •ë³´ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


@router.get("/{file_id}", response_model=TaggingSuggestionDetailResponse)
async def get_tagging_suggestion(file_id: str, db: Session = Depends(get_db)):
    """
    í™”ì íƒœê¹… ì œì•ˆ ì¡°íšŒ
    I,O.md Step 5d - ì‹œìŠ¤í…œì´ ë¶„ì„í•œ ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ì œì•ˆ
    """
    # AudioFile ì°¾ê¸° - ID(ìˆ«ì)ë¡œ ë¨¼ì € ì‹œë„, ì‹¤íŒ¨ì‹œ ë¬¸ìì—´ ê²€ìƒ‰
    audio_file = None
    if file_id.isdigit():
        audio_file = db.query(AudioFile).filter(AudioFile.id == int(file_id)).first()
    if not audio_file:
        audio_file = db.query(AudioFile).filter(
            (AudioFile.file_path.like(f"%{file_id}%")) |
            (AudioFile.original_filename.like(f"%{file_id}%"))
        ).first()

    if not audio_file:
        raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    # STT ê²°ê³¼ ì¡°íšŒ
    stt_results = db.query(STTResult).filter(
        STTResult.audio_file_id == audio_file.id
    ).order_by(STTResult.start_time).all()

    # Diarization ê²°ê³¼ ì¡°íšŒ
    diar_results = db.query(DiarizationResult).filter(
        DiarizationResult.audio_file_id == audio_file.id
    ).order_by(DiarizationResult.start_time).all()

    # STTì™€ Diarization ë³‘í•©
    merged_segments = []
    for stt in stt_results:
        speaker_label = "UNKNOWN"
        for diar in diar_results:
            if diar.start_time <= stt.start_time < diar.end_time:
                speaker_label = diar.speaker_label
                break

        merged_segments.append({
            "speaker": speaker_label,
            "start": stt.start_time,
            "end": stt.end_time,
            "text": stt.text
        })

    # SpeakerMappingì—ì„œ Agentê°€ ì œì•ˆí•œ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
    speaker_mappings = db.query(SpeakerMapping).filter(
        SpeakerMapping.audio_file_id == audio_file.id
    ).all()

    # suggested_mappings êµ¬ì„± (ê¸°ì¡´ final_nameë„ í¬í•¨)
    suggested_mappings = []
    for sm in speaker_mappings:
        suggested_mappings.append(
            SuggestedMapping(
                speaker_label=sm.speaker_label,
                suggested_name=sm.suggested_name,
                nickname=sm.nickname,
                final_name=sm.final_name  # ê¸°ì¡´ í™•ì •ëœ ì´ë¦„
            )
        )

    # ì‚¬ìš©ìê°€ í™•ì •í•œ ì´ë¦„ ë° ë‹‰ë„¤ì„ ëª©ë¡
    user_confirmation = db.query(UserConfirmation).filter(
        UserConfirmation.audio_file_id == audio_file.id
    ).first()

    detected_names = user_confirmation.confirmed_names if user_confirmation and user_confirmation.confirmed_names else []
    detected_nicknames = user_confirmation.confirmed_nicknames if user_confirmation and user_confirmation.confirmed_nicknames else []

    # UserConfirmationì´ ì—†ìœ¼ë©´ DetectedName í…Œì´ë¸”ì—ì„œ ê°€ì ¸ì˜¤ê¸°
    if not detected_names:
        detected_names_query = db.query(DetectedName.detected_name).filter(
            DetectedName.audio_file_id == audio_file.id
        ).distinct().all()
        detected_names = [name[0] for name in detected_names_query if name[0]]

    # ë‹‰ë„¤ì„ì´ ì—†ìœ¼ë©´ SpeakerMappingì—ì„œ ê°€ì ¸ì˜¤ê¸°
    if not detected_nicknames:
        detected_nicknames = [sm.nickname for sm in speaker_mappings if sm.nickname]

    # sample_transcript êµ¬ì„± (ì²˜ìŒ 20ê°œ ì„¸ê·¸ë¨¼íŠ¸)
    sample_transcript = []
    for seg in merged_segments[:20]:
        sample_transcript.append(
            TranscriptSegment(
                speaker_label=seg["speaker"],
                start_time=seg["start"],
                end_time=seg["end"],
                text=seg["text"]
            )
        )

    return TaggingSuggestionDetailResponse(
        file_id=file_id,
        detected_names=detected_names,
        detected_nicknames=detected_nicknames,  # ë‹‰ë„¤ì„ ì¶”ê°€
        suggested_mappings=suggested_mappings,
        sample_transcript=sample_transcript
    )


@router.post("/analyze/{file_id}")
async def analyze_speakers(
    file_id: str,
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db)
):
    """
    LangGraph Agent ì‹¤í–‰ (ë°±ê·¸ë¼ìš´ë“œ)
    I,O.md Step 5a~5c - ë©€í‹°í„´ LLM ì¶”ë¡ ìœ¼ë¡œ í™”ì íƒœê¹…
    """
    # AudioFile ì°¾ê¸°
    audio_file = db.query(AudioFile).filter(
        (AudioFile.file_path.like(f"%{file_id}%")) |
        (AudioFile.original_filename.like(f"%{file_id}%"))
    ).first()

    if not audio_file:
        raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    # ì²˜ë¦¬ ì¤‘ì¸ì§€ í™•ì¸
    from app.models.audio_file import FileStatus
    if audio_file.status == FileStatus.PROCESSING:
         print(f"â³ íŒŒì¼ì´ ì²˜ë¦¬ ì¤‘ì´ë¯€ë¡œ ì—ì´ì „íŠ¸ ì‹¤í–‰ì„ ì˜ˆì•½í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ (ìë™ ì‹¤í–‰ë¨): {file_id}")
         return {
            "file_id": file_id,
            "message": "íŒŒì¼ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤. ì™„ë£Œ í›„ ìë™ìœ¼ë¡œ ë¶„ì„ë©ë‹ˆë‹¤.",
            "status": "processing"
        }

    # Agent ì‹¤í–‰ (ë°±ê·¸ë¼ìš´ë“œ)
    background_tasks.add_task(
        run_tagging_agent,
        file_id=file_id,
        audio_file_id=audio_file.id,
        user_id=audio_file.user_id
    )

    return {
        "file_id": file_id,
        "message": "í™”ì íƒœê¹… ë¶„ì„ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.",
        "status": "processing"
    }


async def run_tagging_agent(file_id: str, audio_file_id: int, user_id: int):
    """
    Agent ì‹¤í–‰ ë° ê²°ê³¼ DB ì €ì¥
    """
    import os
    from app.db.base import SessionLocal
    
    # LangSmith ì¶”ì  í™˜ê²½ ë³€ìˆ˜ í™•ì¸ ë° ìë™ ì¡°ì • (ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ì—ì„œë„ ë™ì‘ í™•ì¸)
    langchain_tracing = os.getenv("LANGCHAIN_TRACING_V2", "false")
    if langchain_tracing.lower() == "true":
        # LANGSMITH_API_KEYë„ í™•ì¸ (ì¼ë¶€ ì„¤ì •ì—ì„œ ì‚¬ìš©)
        langchain_api_key = os.getenv("LANGCHAIN_API_KEY") or os.getenv("LANGSMITH_API_KEY")
        if langchain_api_key and langchain_api_key.strip():
            # LANGCHAIN_API_KEYê°€ ì—†ìœ¼ë©´ LANGSMITH_API_KEYë¥¼ ë³µì‚¬
            if not os.getenv("LANGCHAIN_API_KEY") and os.getenv("LANGSMITH_API_KEY"):
                os.environ["LANGCHAIN_API_KEY"] = os.getenv("LANGSMITH_API_KEY")
            print(f"ğŸ” LangSmith ì¶”ì  í™œì„±í™”: file_id={file_id}, audio_file_id={audio_file_id}")
        else:
            # API í‚¤ê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ì¶”ì  ë¹„í™œì„±í™” (ì—ëŸ¬ ë°©ì§€)
            os.environ["LANGCHAIN_TRACING_V2"] = "false"
            print(f"âš ï¸ LANGCHAIN_TRACING_V2=trueì´ì§€ë§Œ LANGCHAIN_API_KEY ë˜ëŠ” LANGSMITH_API_KEYê°€ ì—†ì–´ì„œ ì¶”ì ì„ ë¹„í™œì„±í™”í–ˆìŠµë‹ˆë‹¤. file_id={file_id}")
    else:
        print(f"â„¹ï¸ LangSmith ì¶”ì  ë¹„í™œì„±í™”: file_id={file_id}")
    
    # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ìš© ìƒˆ DB ì„¸ì…˜ ìƒì„±
    db = SessionLocal()
    
    try:
        # 1. DBì—ì„œ ë°ì´í„° ë¡œë“œ
        agent_input = load_agent_input_data_by_file_id(file_id, db)
        
        # 2. AgentState êµ¬ì„±
        initial_state = {
            "user_id": user_id,
            "audio_file_id": audio_file_id,
            "stt_result": agent_input["stt_result"],
            "diar_result": agent_input["diar_result"],
            "participant_names": agent_input.get("participant_names", []),
            "previous_profiles": [],
            "auto_matched": {},
            "name_mentions": agent_input["name_mentions"],
            "speaker_utterances": {},
            "mapping_history": [],
            "name_based_results": {},
            "final_mappings": {},
            "needs_manual_review": []
        }

        # 3. Agent ì‹¤í–‰ (LangSmith ì¶”ì  í¬í•¨)
        app = get_speaker_tagging_app()
        
        # LangSmith ì¶”ì ì„ ìœ„í•œ config ì„¤ì •
        # ê° ì‹¤í–‰ì„ êµ¬ë¶„í•˜ê¸° ìœ„í•´ run_nameê³¼ metadata ì¶”ê°€
        config = {
            "configurable": {
                "thread_id": f"audio_file_{audio_file_id}",
            },
            "metadata": {
                "file_id": file_id,
                "audio_file_id": audio_file_id,
                "user_id": user_id,
                "run_name": f"speaker_tagging_{file_id}",
            }
        }
        
        final_state = await app.ainvoke(initial_state, config=config)

        # 4. ê²°ê³¼ë¥¼ SpeakerMapping í…Œì´ë¸”ì— ì €ì¥
        final_mappings = final_state.get("final_mappings", {})
        
        for speaker_label, mapping_info in final_mappings.items():
            # ê¸°ì¡´ SpeakerMapping ì°¾ê¸°
            speaker_mapping = db.query(SpeakerMapping).filter(
                SpeakerMapping.audio_file_id == audio_file_id,
                SpeakerMapping.speaker_label == speaker_label
            ).first()

            if speaker_mapping:
                # ì—…ë°ì´íŠ¸
                speaker_mapping.suggested_name = mapping_info.get("name")
                speaker_mapping.name_confidence = mapping_info.get("confidence")
                speaker_mapping.name_mentions = len([
                    m for m in final_state.get("name_mentions", [])
                    if m.get("name") == mapping_info.get("name")
                ])
                speaker_mapping.needs_manual_review = mapping_info.get("needs_review", False)
                speaker_mapping.conflict_detected = False  # name_basedë§Œ ì‚¬ìš©í•˜ë¯€ë¡œ conflict ì—†ìŒ
            else:
                # ìƒˆë¡œ ìƒì„±
                speaker_mapping = SpeakerMapping(
                    audio_file_id=audio_file_id,
                    speaker_label=speaker_label,
                    suggested_name=mapping_info.get("name"),
                    name_confidence=mapping_info.get("confidence"),
                    name_mentions=len([
                        m for m in final_state.get("name_mentions", [])
                        if m.get("name") == mapping_info.get("name")
                    ]),
                    suggested_role=None,
                    role_confidence=None,
                    conflict_detected=False,
                    needs_manual_review=mapping_info.get("needs_review", False),
                    final_name="",
                    is_modified=False
                )
                db.add(speaker_mapping)

        db.commit()
        print(f"âœ… Agent ì‹¤í–‰ ì™„ë£Œ: audio_file_id={audio_file_id}, ë§¤í•‘ {len(final_mappings)}ê°œ ì €ì¥")

    except Exception as e:
        print(f"âš ï¸ Agent ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        db.rollback()
        import traceback
        traceback.print_exc()
    finally:
        db.close()


@router.post("/confirm", response_model=TaggingConfirmResponse)
async def confirm_tagging(
    request: TaggingConfirmRequest,
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db)
):
    """
    í™”ì íƒœê¹… í™•ì •
    I,O.md Step 5e - ì‚¬ìš©ìê°€ ìµœì¢… í™•ì •í•œ í™”ì ì´ë¦„ ì €ì¥
    """
    # AudioFile ì°¾ê¸° - ID(ìˆ«ì)ë¡œ ë¨¼ì € ì‹œë„, ì‹¤íŒ¨ì‹œ ë¬¸ìì—´ ê²€ìƒ‰
    audio_file = None
    if request.file_id.isdigit():
        audio_file = db.query(AudioFile).filter(AudioFile.id == int(request.file_id)).first()
    if not audio_file:
        audio_file = db.query(AudioFile).filter(
            (AudioFile.file_path.like(f"%{request.file_id}%")) |
            (AudioFile.original_filename.like(f"%{request.file_id}%"))
        ).first()

    if not audio_file:
        raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    # í™”ìëª… ë³€ê²½ ê°ì§€ ë° ë²¡í„° DB ì‚­ì œ
    needs_rag_reinit = False
    if audio_file.rag_initialized:
        # ê¸°ì¡´ ë§¤í•‘ê³¼ ë¹„êµí•˜ì—¬ ë³€ê²½ ì—¬ë¶€ í™•ì¸
        existing_mappings = db.query(SpeakerMapping).filter(
            SpeakerMapping.audio_file_id == audio_file.id
        ).all()
        existing_final_names = {sm.speaker_label: sm.final_name for sm in existing_mappings if sm.final_name}
        
        # ìƒˆë¡œìš´ ë§¤í•‘ê³¼ ë¹„êµ
        for mapping in request.mappings:
            old_name = existing_final_names.get(mapping.speaker_label)
            if old_name and old_name != mapping.final_name:
                needs_rag_reinit = True
                break
        
        # ë²¡í„° DB ì‚­ì œ
        if needs_rag_reinit:
            from app.services.rag_service import RAGService
            rag_service = RAGService()
            rag_service.delete_collection(str(audio_file.id))
            audio_file.rag_initialized = False
            audio_file.rag_collection_name = None
            audio_file.rag_initialized_at = None

    # SpeakerMapping ì—…ë°ì´íŠ¸
    for mapping in request.mappings:
        speaker_mapping = db.query(SpeakerMapping).filter(
            SpeakerMapping.audio_file_id == audio_file.id,
            SpeakerMapping.speaker_label == mapping.speaker_label
        ).first()

        if speaker_mapping:
            # ì‚¬ìš©ìê°€ ìˆ˜ì •í–ˆëŠ”ì§€ í™•ì¸
            is_modified = speaker_mapping.suggested_name != mapping.final_name
            
            speaker_mapping.final_name = mapping.final_name
            speaker_mapping.is_modified = is_modified
        else:
            # ìƒˆë¡œ ìƒì„±
            speaker_mapping = SpeakerMapping(
                audio_file_id=audio_file.id,
                speaker_label=mapping.speaker_label,
                suggested_name=None,
                name_confidence=None,
                name_mentions=0,
                suggested_role=None,
                role_confidence=None,
                conflict_detected=False,
                needs_manual_review=False,
                final_name=mapping.final_name,
                is_modified=True
            )
            db.add(speaker_mapping)

    # FinalTranscript ìƒì„±/ì—…ë°ì´íŠ¸ (Step 5f)
    from app.models.transcript import FinalTranscript
    from app.models.stt import STTResult
    from app.models.diarization import DiarizationResult
    
    # ê¸°ì¡´ FinalTranscript ì‚­ì œ (ì¬ìƒì„±ì„ ìœ„í•´)
    db.query(FinalTranscript).filter(
        FinalTranscript.audio_file_id == audio_file.id
    ).delete()
    
    # STT ê²°ê³¼ ì¡°íšŒ
    stt_results = db.query(STTResult).filter(
        STTResult.audio_file_id == audio_file.id
    ).order_by(STTResult.start_time).all()

    # Diarization ê²°ê³¼ ì¡°íšŒ
    diar_results = db.query(DiarizationResult).filter(
        DiarizationResult.audio_file_id == audio_file.id
    ).order_by(DiarizationResult.start_time).all()

    # SpeakerMappingì—ì„œ final_name ê°€ì ¸ì˜¤ê¸°
    speaker_mappings = db.query(SpeakerMapping).filter(
        SpeakerMapping.audio_file_id == audio_file.id
    ).all()
    mappings = {sm.speaker_label: sm.final_name for sm in speaker_mappings if sm.final_name}

    # FinalTranscript ìƒì„±
    for idx, stt in enumerate(stt_results):
        speaker_label = "UNKNOWN"
        for diar in diar_results:
            if diar.start_time <= stt.start_time < diar.end_time:
                speaker_label = diar.speaker_label
                break

        # final_name ë§¤í•‘ ì ìš© (ì—†ìœ¼ë©´ speaker_label ì‚¬ìš©)
        speaker_name = mappings.get(speaker_label, speaker_label)

        final_transcript = FinalTranscript(
            audio_file_id=audio_file.id,
            segment_index=idx,
            speaker_name=speaker_name,
            start_time=stt.start_time,
            end_time=stt.end_time,
            text=stt.text
        )
        db.add(final_transcript)

    db.commit()

    # í™”ì í”„ë¡œí•„ ìë™ ì €ì¥
    from app.models.speaker_profile import SpeakerProfile
    from app.models.diarization import DiarizationResult
    from openai import OpenAI
    from app.core.config import settings
    import numpy as np

    profiles_saved = 0
    for mapping in request.mappings:
        if not mapping.final_name or mapping.final_name.strip() == "":
            continue  # ì´ë¦„ì´ ì—†ìœ¼ë©´ ìŠ¤í‚µ

        # ì´ë¯¸ í”„ë¡œí•„ì´ ìˆëŠ”ì§€ í™•ì¸
        existing_profile = db.query(SpeakerProfile).filter(
            SpeakerProfile.user_id == audio_file.user_id,
            SpeakerProfile.speaker_name == mapping.final_name
        ).first()

        if existing_profile:
            # ê¸°ì¡´ í”„ë¡œí•„ ì—…ë°ì´íŠ¸ (ì‹ ë¢°ë„ ì¦ê°€)
            existing_profile.confidence_score += 1
            existing_profile.source_audio_file_id = audio_file.id
            profiles_saved += 1
            continue

        # ìƒˆ í”„ë¡œí•„ ìƒì„±
        try:
            # 1. ìŒì„± ì„ë² ë”© í‰ê·  ê³„ì‚°
            diar_results = db.query(DiarizationResult).filter(
                DiarizationResult.audio_file_id == audio_file.id,
                DiarizationResult.speaker_label == mapping.speaker_label
            ).all()

            embeddings = [np.array(d.embedding) for d in diar_results if d.embedding]
            voice_embedding = np.mean(embeddings, axis=0).tolist() if embeddings else None

            # 2. í…ìŠ¤íŠ¸ ìƒ˜í”Œ ì¶”ì¶œ
            sample_texts = []
            for diar in diar_results[:5]:
                segment_texts = [
                    stt.text for stt in stt_results
                    if diar.start_time <= stt.start_time < diar.end_time
                ]
                if segment_texts:
                    sample_texts.append(" ".join(segment_texts))

            # 3. í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
            text_embedding = None
            if sample_texts:
                try:
                    client = OpenAI(api_key=settings.OPENAI_API_KEY)
                    combined_text = " ".join(sample_texts)
                    response = client.embeddings.create(
                        model="text-embedding-3-small",
                        input=combined_text
                    )
                    text_embedding = response.data[0].embedding
                except Exception as e:
                    print(f"âš ï¸ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")

            # 4. í”„ë¡œí•„ ì €ì¥
            new_profile = SpeakerProfile(
                user_id=audio_file.user_id,
                speaker_name=mapping.final_name,
                voice_embedding=voice_embedding,
                text_embedding=text_embedding,
                sample_texts=sample_texts,
                source_audio_file_id=audio_file.id,
                confidence_score=1
            )
            db.add(new_profile)
            profiles_saved += 1
            print(f"âœ… í”„ë¡œí•„ ì €ì¥: {mapping.final_name} (í™”ì: {mapping.speaker_label})")
        except Exception as e:
            print(f"âš ï¸ í”„ë¡œí•„ ì €ì¥ ì‹¤íŒ¨ ({mapping.final_name}): {e}")

    db.commit()

    if profiles_saved > 0:
        print(f"âœ… {profiles_saved}ê°œ í™”ì í”„ë¡œí•„ ìë™ ì €ì¥ ì™„ë£Œ")

    # í™”ì íƒœê¹… ì™„ë£Œ í›„ íš¨ìœ¨ì„± ë¶„ì„ ìë™ ì‹¤í–‰
    from app.api.v1.efficiency import run_efficiency_analysis
    from app.models.efficiency import MeetingEfficiencyAnalysis
    
    # ê¸°ì¡´ íš¨ìœ¨ì„± ë¶„ì„ ê²°ê³¼ ì‚­ì œ (ì¬ë¶„ì„ ì‹œ stale data ë°©ì§€)
    # ì‚­ì œí•˜ë©´ í”„ë¡ íŠ¸ì—”ë“œëŠ” 404ë¥¼ ë°›ê³  ë¡œì»¬ ê³„ì‚°(ì˜¬ë°”ë¥¸ ì´ë¦„)ìœ¼ë¡œ í´ë°±í•¨
    db.query(MeetingEfficiencyAnalysis).filter(
        MeetingEfficiencyAnalysis.audio_file_id == audio_file.id
    ).delete()
    db.commit()
    print(f"ğŸ§¹ ê¸°ì¡´ íš¨ìœ¨ì„± ë¶„ì„ ê²°ê³¼ ì‚­ì œ ì™„ë£Œ: {audio_file.id}")

    print(f"ğŸš€ [Tagging] Triggering background efficiency analysis for file {audio_file.id}")
    background_tasks.add_task(run_efficiency_analysis, str(audio_file.id))

    # êµ¬ê°„ ë¶„ì„(í…œí”Œë¦¿ í”¼íŒ…) ìë™ ì‹¤í–‰
    from app.services.template_generator import run_template_generation_background
    background_tasks.add_task(run_template_generation_background, audio_file.id)

    response_message = f"í™”ì íƒœê¹…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. {profiles_saved}ê°œ í”„ë¡œí•„ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."
    if needs_rag_reinit:
        response_message += " í™”ìëª…ì´ ë³€ê²½ë˜ì–´ ë²¡í„° DBê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. RAG ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ì‹œ ì´ˆê¸°í™”í•´ì£¼ì„¸ìš”."

    return TaggingConfirmResponse(
        file_id=request.file_id,
        message=response_message,
        status="confirmed"
    )


@router.get("/{file_id}/result")
async def get_tagging_result(file_id: str, db: Session = Depends(get_db)):
    """
    í™•ì •ëœ íƒœê¹… ê²°ê³¼ ì¡°íšŒ
    I,O.md Step 5f - ì‚¬ìš©ìê°€ í™•ì •í•œ í™”ì ì´ë¦„ì´ ì ìš©ëœ ìµœì¢… ëŒ€ë³¸
    """
    # AudioFile ì°¾ê¸° - ID(ìˆ«ì)ë¡œ ë¨¼ì € ì‹œë„, ì‹¤íŒ¨ì‹œ ë¬¸ìì—´ ê²€ìƒ‰
    audio_file = None
    if file_id.isdigit():
        audio_file = db.query(AudioFile).filter(AudioFile.id == int(file_id)).first()

    if not audio_file:
        audio_file = db.query(AudioFile).filter(
            (AudioFile.file_path.like(f"%{file_id}%")) |
            (AudioFile.original_filename.like(f"%{file_id}%"))
        ).first()

    if not audio_file:
        raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    # SpeakerMappingì—ì„œ final_name ê°€ì ¸ì˜¤ê¸°
    speaker_mappings = db.query(SpeakerMapping).filter(
        SpeakerMapping.audio_file_id == audio_file.id
    ).all()

    # final_nameì´ ìˆëŠ”ì§€ í™•ì¸
    mappings = {sm.speaker_label: sm.final_name for sm in speaker_mappings if sm.final_name}
    
    if not mappings:
        raise HTTPException(
            status_code=404,
            detail="íƒœê¹… ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € íƒœê¹…ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”."
        )

    # STT ê²°ê³¼ ì¡°íšŒ
    stt_results = db.query(STTResult).filter(
        STTResult.audio_file_id == audio_file.id
    ).order_by(STTResult.start_time).all()

    # Diarization ê²°ê³¼ ì¡°íšŒ
    diar_results = db.query(DiarizationResult).filter(
        DiarizationResult.audio_file_id == audio_file.id
    ).order_by(DiarizationResult.start_time).all()

    # STTì™€ Diarization ë³‘í•©í•˜ì—¬ ìµœì¢… ëŒ€ë³¸ ìƒì„±
    final_transcript = []
    for stt in stt_results:
        speaker_label = "UNKNOWN"
        for diar in diar_results:
            if diar.start_time <= stt.start_time < diar.end_time:
                speaker_label = diar.speaker_label
                break

        # final_name ë§¤í•‘ ì ìš©
        speaker_name = mappings.get(speaker_label, "Unknown")

        final_transcript.append({
            "speaker_name": speaker_name,
            "speaker_label": speaker_label,
            "start_time": stt.start_time,
            "end_time": stt.end_time,
            "text": stt.text
        })

    return {
        "file_id": file_id,
        "audio_file_id": audio_file.id,  # RAG ë“±ì—ì„œ ì‚¬ìš©í•  ìˆ«ì ID
        "status": "confirmed",
        "mappings": mappings,
        "final_transcript": final_transcript,
        "total_segments": len(final_transcript)
    }
