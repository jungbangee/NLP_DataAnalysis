"""
name_based_tagging_node
ì´ë¦„ ê¸°ë°˜ í™”ì íƒœê¹… (ëŒ€í™”íë¦„.ipynb ë¡œì§ ì¬ì‚¬ìš©)
"""
from typing import List, Dict
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field
from app.core.config import settings
from app.agents.state import AgentState
from app.agents.prompts.name_based_prompt import create_name_based_prompt


class SpeakerMappingResult(BaseModel):
    """LLM ì‘ë‹µ íŒŒì‹±ìš© ëª¨ë¸"""
    speaker: str = Field(description="Speaker ID (ì˜ˆ: SPEAKER_00)")
    name: str = Field(description="ì°¸ì—¬ì ì´ë¦„ (ë°˜ë“œì‹œ system í”„ë¡¬í”„íŠ¸ì˜ 'ì°¸ì—¬ì ì´ë¦„ ëª©ë¡'ì— ìˆëŠ” ì´ë¦„ ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•¨)")
    confidence: float = Field(description="í™•ì‹ ë„ 0.0~1.0", ge=0.0, le=1.0)
    reasoning: str = Field(description="íŒë‹¨ ê·¼ê±°")


async def name_based_tagging_node(state: AgentState) -> AgentState:
    """
    ë°©ì‹1: ì´ë¦„ ê¸°ë°˜ íƒœê¹…
    - LLMì—ê²Œ ëŒ€í™” íë¦„ì„ ë³´ì—¬ì£¼ê³  "ë¯¼ì„œëŠ” SPEAKER_00? SPEAKER_01?" íŒë‹¨
    - ëŒ€í™”íë¦„.ipynbì˜ LangChainSpeakerMapper ë¡œì§ ì¬ì‚¬ìš©
    """
    import os
    name_mentions = state.get("name_mentions", [])
    participant_names = state.get("participant_names", [])
    mapping_history = state.get("mapping_history", [])
    
    if not name_mentions:
        state["name_based_results"] = {}
        return state

    # LangSmith ì¶”ì  í™˜ê²½ ë³€ìˆ˜ í™•ì¸ ë° ì¡°ì • (API í‚¤ê°€ ì—†ìœ¼ë©´ ë¹„í™œì„±í™”)
    langchain_tracing = os.getenv("LANGCHAIN_TRACING_V2", "false")
    if langchain_tracing.lower() == "true":
        # LANGSMITH_API_KEYë„ í™•ì¸ (ì¼ë¶€ ì„¤ì •ì—ì„œ ì‚¬ìš©)
        langchain_api_key = os.getenv("LANGCHAIN_API_KEY") or os.getenv("LANGSMITH_API_KEY")
        if langchain_api_key and langchain_api_key.strip():
            # LANGCHAIN_API_KEYê°€ ì—†ìœ¼ë©´ LANGSMITH_API_KEYë¥¼ ë³µì‚¬
            if not os.getenv("LANGCHAIN_API_KEY") and os.getenv("LANGSMITH_API_KEY"):
                os.environ["LANGCHAIN_API_KEY"] = os.getenv("LANGSMITH_API_KEY")
        else:
            # API í‚¤ê°€ ì—†ìœ¼ë©´ ì¶”ì  ë¹„í™œì„±í™” (ì—ëŸ¬ ë°©ì§€)
            os.environ["LANGCHAIN_TRACING_V2"] = "false"

    # LLM ì´ˆê¸°í™”
    # LLM ì´ˆê¸°í™”
    # gpt-5-mini ëª¨ë¸ì€ temperature ê¸°ë³¸ê°’(1)ë§Œ ì§€ì›í•˜ë¯€ë¡œ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
    model_name = "gpt-5-mini-2025-08-07"
    
    print(f"ğŸ” [NameBasedTagging] Processing {len(name_mentions)} name mentions using {model_name}")

    # temperature ì„¤ì •
    # gpt-5-miniëŠ” ê¸°ë³¸ê°’(1)ë§Œ ì§€ì›í•˜ë¯€ë¡œ temperature=1 ëª…ì‹œ
    # ë‹¤ë¥¸ ëª¨ë¸ì€ temperature=0.3 ì‚¬ìš©
    if model_name.startswith("gpt-5-mini"):
        llm = ChatOpenAI(
            model=model_name,
            temperature=1.0,  # gpt-5-miniëŠ” ê¸°ë³¸ê°’(1)ë§Œ ì§€ì›
            api_key=settings.OPENAI_API_KEY
        )
    else:
        llm = ChatOpenAI(
            model=model_name,
            temperature=0.3,
            api_key=settings.OPENAI_API_KEY
        )

    # PydanticOutputParser ì´ˆê¸°í™”
    output_parser = PydanticOutputParser(pydantic_object=SpeakerMappingResult)
    format_instructions = output_parser.get_format_instructions()

    name_results = {}
    
    # ê° ì´ë¦„ ì–¸ê¸‰ì— ëŒ€í•´ LLM í˜¸ì¶œ (ëŒ€í™”íë¦„.ipynbì™€ ë™ì¼í•˜ê²Œ)
    for turn_num, mention in enumerate(name_mentions, 1):
        name = mention.get("name")
        context_before = mention.get("context_before", [])
        context_after = mention.get("context_after", [])
        time_detected = mention.get("time", 0.0)
        target_text = mention.get("target_text")  # ì‹¤ì œ ì´ë¦„ì´ ì–¸ê¸‰ëœ ë¬¸ì¥
        target_speaker = mention.get("target_speaker")  # target ë¬¸ì¥ì˜ í™”ì

        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        system_message, user_message = create_name_based_prompt(
            name=name,
            context_before=context_before,
            context_after=context_after,
            participant_names=participant_names,
            mapping_history=mapping_history,
            turn_num=turn_num,
            format_instructions=format_instructions,
            target_text=target_text,
            target_speaker=target_speaker
        )

        try:
            # LLM í˜¸ì¶œ
            messages = [
                {"role": "system", "content": system_message},
                {"role": "user", "content": user_message}
            ]

            # LLM í˜¸ì¶œ (LangChain ì‚¬ìš© - LangSmith ìë™ ì¶”ì )
            response = llm.invoke(messages)
            response_content = response.content
            
            result_obj = output_parser.parse(response_content)

            result = {
                "speaker": result_obj.speaker,
                "name": result_obj.name,
                "confidence": result_obj.confidence,
                "reasoning": result_obj.reasoning,
                "turn": turn_num,
                "time": time_detected,
                "name_mentioned": name
            }

            # mapping_historyì— ì¶”ê°€
            mapping_history.append(result)

            # ê°™ì€ ì´ë¦„ì— ëŒ€í•œ ì—¬ëŸ¬ ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥
            if name not in name_results:
                name_results[name] = []
            name_results[name].append(result)

        except Exception as e:
            # ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            result = {
                "speaker": "Unknown",
                "name": "Unknown",
                "confidence": 0.0,
                "reasoning": f"ì—ëŸ¬: {str(e)[:100]}",
                "turn": turn_num,
                "time": time_detected,
                "name_mentioned": name,
                "error": str(e)[:200]
            }
            mapping_history.append(result)

    state["name_based_results"] = name_results
    state["mapping_history"] = mapping_history

    return state

