"""
LangGraph ê¸°ë°˜ íšŒì˜ë¡ ìƒì„± ì›Œí¬í”Œë¡œìš°
ë³µì¡í•œ íšŒì˜ë¡ ìƒì„± ê³¼ì •ì„ êµ¬ì¡°í™”ëœ ê·¸ë˜í”„ë¡œ ê´€ë¦¬
"""
import io
from typing import Dict, List, Tuple, Any, TypedDict
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field

from docx import Document
from .meeting_minutes_service import (
    MeetingAnalysis,
    get_prompt_template,
    process_signature_table,
    process_paragraphs,
    fill_element,
    clean_header,
    format_text_content
)


# -------------------------------------------------------
# State ì •ì˜
# -------------------------------------------------------
class MeetingMinutesState(TypedDict):
    """íšŒì˜ë¡ ìƒì„± ì›Œí¬í”Œë¡œìš°ì˜ ìƒíƒœ"""
    # ì…ë ¥ ë°ì´í„°
    transcript_data: List[Tuple[str, str]]
    speakers: List[str]
    file_info: Dict[str, Any]
    template_path: str
    api_key: str
    form_type: int

    # ì¤‘ê°„ ê²°ê³¼
    transcript_text: str
    analysis_result: Dict[str, Any]
    formatted_data: Dict[str, str]

    # ìµœì¢… ê²°ê³¼
    output_docx: io.BytesIO
    error: str


# -------------------------------------------------------
# ë…¸ë“œ í•¨ìˆ˜ë“¤
# -------------------------------------------------------
def prepare_transcript(state: MeetingMinutesState) -> MeetingMinutesState:
    """Step 1: ë…¹ì·¨ë¡ í…ìŠ¤íŠ¸ ì¤€ë¹„"""
    print("ğŸ“ [Step 1/4] ë…¹ì·¨ë¡ í…ìŠ¤íŠ¸ ì¤€ë¹„ ì¤‘...")

    transcript_text = "\n".join([
        f"{speaker}: {text}"
        for speaker, text in state["transcript_data"]
    ])

    state["transcript_text"] = transcript_text
    print(f"  âœ“ {len(state['transcript_data'])} ê°œ ë°œí™” ì¤€ë¹„ ì™„ë£Œ")
    return state


def analyze_with_llm(state: MeetingMinutesState) -> MeetingMinutesState:
    """Step 2: LangChain + GPTë¡œ ë¶„ì„"""
    print("ğŸ¤– [Step 2/4] AI ë¶„ì„ ì¤‘...")

    try:
        llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0,
            openai_api_key=state["api_key"]
        )

        parser = PydanticOutputParser(pydantic_object=MeetingAnalysis)

        prompt = PromptTemplate(
            template=get_prompt_template(state["form_type"]),
            input_variables=["transcript"],
            partial_variables={"format_instructions": parser.get_format_instructions()}
        )

        chain = prompt | llm | parser

        # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (í† í° ì œí•œ ë°©ì§€)
        result_obj = chain.invoke({"transcript": state["transcript_text"][:15000]})

        # Pydantic v2 í˜¸í™˜
        try:
            result_dict = result_obj.model_dump()
        except AttributeError:
            result_dict = result_obj.dict()

        state["analysis_result"] = result_dict
        print(f"  âœ“ AI ë¶„ì„ ì™„ë£Œ (ì•ˆê±´: {result_dict.get('agenda', 'N/A')[:30]}...)")

    except Exception as e:
        print(f"  âœ— AI ë¶„ì„ ì‹¤íŒ¨: {e}")
        state["error"] = f"AI analysis failed: {str(e)}"
        state["analysis_result"] = {
            "agenda": "ë¶„ì„ ì‹¤íŒ¨",
            "summary": "íšŒì˜ë¡ ìë™ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "key_decisions": "ì—†ìŒ",
            "action_items": "ì—†ìŒ",
            "issues": "ì—†ìŒ",
            "next_agenda": "ì—†ìŒ",
            "keywords": "",
            "date": ""
        }

    return state


def format_data(state: MeetingMinutesState) -> MeetingMinutesState:
    """Step 3: ë°ì´í„° í¬ë§·íŒ…"""
    print("ğŸ“‹ [Step 3/4] ë°ì´í„° í¬ë§·íŒ… ì¤‘...")

    participants = ", ".join(state["speakers"])
    analysis = state["analysis_result"]

    formatted_data = {
        "DATE": analysis.get("date") or str(state["file_info"].get("created_at", ""))[:10],
        "PARTICIPANTS": participants,
        "SUMMARY": analysis.get("summary", ""),
        "AGENDA": analysis.get("agenda", ""),
        "DECISIONS": analysis.get("key_decisions", ""),
        "ACTION_ITEMS": analysis.get("action_items", ""),
        "KEYWORDS": analysis.get("keywords", ""),
        "ISSUES": analysis.get("issues", ""),
        "NEXT_AGENDA": analysis.get("next_agenda", "")
    }

    state["formatted_data"] = formatted_data
    print("  âœ“ ë°ì´í„° í¬ë§·íŒ… ì™„ë£Œ")
    return state


def generate_docx(state: MeetingMinutesState) -> MeetingMinutesState:
    """Step 4: Word ë¬¸ì„œ ìƒì„±"""
    print("ğŸ“„ [Step 4/4] Word ë¬¸ì„œ ìƒì„± ì¤‘...")

    try:
        doc = Document(state["template_path"])
        data = state["formatted_data"]

        # í—¤ë” ë§¤í•‘
        header_map = {
            "ì¼ì‹œ": "DATE", "ë‚ ì§œ": "DATE", "íšŒì˜ì¼ì": "DATE", "íšŒì˜ë‚ ì§œ": "DATE", "íšŒì˜ì¼ì‹œ": "DATE",
            "ì°¸ì„ì": "PARTICIPANTS", "íšŒì˜ì°¸ì„ì": "PARTICIPANTS",
            "íšŒì˜ì•ˆê±´": "AGENDA", "ì£¼ì œ": "AGENDA", "íšŒì˜ì£¼ì œ": "AGENDA", "ì•ˆê±´": "AGENDA",
            "ë‚´ìš©": "SUMMARY", "íšŒì˜ë‚´ìš©": "SUMMARY", "ì£¼ìš”ì•ˆê±´ë°ë‚´ìš©": "SUMMARY",
            "ê²°ê³¼": "DECISIONS", "ê²°ì •ì‚¬í•­": "DECISIONS", "íšŒì˜ê²°ê³¼": "DECISIONS",
            "ê³„íš": "ACTION_ITEMS", "í–¥í›„ê³„íš": "ACTION_ITEMS", "ì§„í–‰ì¼ì •": "ACTION_ITEMS",
            "ë¹„ê³ ": "KEYWORDS", "ì´ìŠˆ": "KEYWORDS", "ì˜ê²¬ì‚¬í•­": "ISSUES", "ì˜ê²¬": "ISSUES",
            "ë‹¤ìŒíšŒì˜": "NEXT_AGENDA"
        }

        column_map = {
            "íšŒì˜ë‚´ìš©": {"main": "SUMMARY", "ì´ìŠˆ": "ISSUES", "ë¹„ê³ ": "ISSUES"},
            "ê²°ì •ì‚¬í•­": {"main": "DECISIONS", "ì§„í–‰ì¼ì •": "ACTION_ITEMS", "ê³„íš": "ACTION_ITEMS"}
        }

        # í‘œ ì²˜ë¦¬
        for table in doc.tables:
            if process_signature_table(table, data["PARTICIPANTS"]):
                continue

            rows = table.rows
            if not rows:
                continue
            first_header = clean_header(rows[0].cells[0].text)

            # ë©€í‹° ì»¬ëŸ¼ í‘œ ì²˜ë¦¬
            is_multi_column = False
            target_col_map = None
            for key, mapping in column_map.items():
                if key in first_header:
                    header_cells_txt = [clean_header(c.text) for c in rows[0].cells]
                    has_sub_col = False
                    for txt in header_cells_txt[1:]:
                        if "ë‚´ìš©" in txt or "Content" in txt:
                            has_sub_col = True
                        for sub_k in mapping.keys():
                            if sub_k != "main" and sub_k in txt:
                                has_sub_col = True
                    if has_sub_col:
                        is_multi_column = True
                        target_col_map = mapping
                        break

            if is_multi_column and target_col_map:
                col_indices = {}
                for idx, cell in enumerate(rows[0].cells):
                    txt = clean_header(cell.text)
                    # ì²« ë²ˆì§¸ ì¹¼ëŸ¼ (main) ê°ì§€: "íšŒì˜ë‚´ìš©", "ê²°ì •ì‚¬í•­" ë“±
                    if idx == 0 or (first_header in txt):
                        col_indices[target_col_map["main"]] = idx
                    # ë‘ ë²ˆì§¸ ì¹¼ëŸ¼ (side) ê°ì§€: "ì´ìŠˆ", "ë¹„ê³ ", "ì§„í–‰ì¼ì •" ë“±
                    for k, v in target_col_map.items():
                        if k != "main" and k in txt:
                            col_indices[v] = idx

                main_data = format_text_content(data.get(target_col_map["main"], "")).split('\n')
                main_data = [l.strip() for l in main_data if l.strip()]

                side_key = None
                side_data = []
                for k in col_indices:
                    if k != target_col_map["main"]:
                        side_key = k
                        side_data = format_text_content(data.get(k, "")).split('\n')
                        side_data = [l.strip() for l in side_data if l.strip()]
                        break

                max_len = max(len(main_data), len(side_data))

                # ëª¨ë“  ë°ì´í„°ë¥¼ í…Œì´ë¸”ì— ë„£ê¸°
                for i in range(max_len):
                    target_row_idx = i + 1
                    # í–‰ì´ ë¶€ì¡±í•˜ë©´ ë™ì ìœ¼ë¡œ ì¶”ê°€
                    while target_row_idx >= len(table.rows):
                        table.add_row()
                    row = table.rows[target_row_idx]

                    main_col_idx = col_indices.get(target_col_map["main"])
                    if main_col_idx is not None:
                        if i < len(main_data):
                            fill_element(row.cells[main_col_idx], main_data[i])
                        else:
                            row.cells[main_col_idx].text = ""

                    if side_key:
                        side_col_idx = col_indices.get(side_key)
                        if side_col_idx is not None:
                            if i < len(side_data):
                                fill_element(row.cells[side_col_idx], side_data[i])
                            else:
                                row.cells[side_col_idx].text = ""

                # ë¹ˆ í–‰ ì‚­ì œ (ëª¨ë“  ì…€ì´ ë¹„ì–´ìˆëŠ” í–‰)
                rows_to_delete = []
                for row_idx in range(1, len(table.rows)):  # í—¤ë” í–‰(0)ì€ ì œì™¸
                    row = table.rows[row_idx]
                    # ëª¨ë“  ì…€ì´ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
                    is_empty = all(cell.text.strip() == "" for cell in row.cells)
                    if is_empty:
                        rows_to_delete.append(row)

                # ì—­ìˆœìœ¼ë¡œ ì‚­ì œ (ì¸ë±ìŠ¤ ì˜¤ë¥˜ ë°©ì§€)
                for row in reversed(rows_to_delete):
                    tbl = table._element
                    tr = row._element
                    tbl.remove(tr)

                print(f"  [í‘œ] '{first_header}' (ë©€í‹° ì»¬ëŸ¼) ì‘ì„± ì™„ë£Œ - {len(rows_to_delete)}ê°œ ë¹ˆ í–‰ ì‚­ì œ")
                continue

            # ì¼ë°˜ í‘œ ì²˜ë¦¬ (ê°„ì†Œí™”)
            r_idx = 0
            while r_idx < len(rows):
                row = rows[r_idx]
                if not row.cells:
                    r_idx += 1
                    continue

                cell_text_raw = row.cells[0].text.strip()
                header_text = clean_header(cell_text_raw)

                found_key = None
                for h_key, d_key in header_map.items():
                    if h_key in header_text:
                        found_key = d_key
                        break

                if found_key and len(row.cells) > 1:
                    raw_content = data.get(found_key, "")
                    formatted_content = format_text_content(raw_content)
                    fill_element(row.cells[1], formatted_content)

                r_idx += 1

        # ëª¨ë“  í‘œì—ì„œ ë¹ˆ í–‰ ì‚­ì œ (í—¤ë” í–‰ ì œì™¸)
        print("ğŸ§¹ ë¹ˆ í–‰ ì •ë¦¬ ì¤‘...")
        for table in doc.tables:
            rows_to_delete = []
            for row_idx in range(1, len(table.rows)):  # í—¤ë” í–‰(0)ì€ ì œì™¸
                row = table.rows[row_idx]
                # ëª¨ë“  ì…€ì´ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
                is_empty = all(cell.text.strip() == "" for cell in row.cells)
                if is_empty:
                    rows_to_delete.append(row)

            # ì—­ìˆœìœ¼ë¡œ ì‚­ì œ
            for row in reversed(rows_to_delete):
                tbl = table._element
                tr = row._element
                tbl.remove(tr)

            if len(rows_to_delete) > 0:
                print(f"  âœ“ í‘œì—ì„œ {len(rows_to_delete)}ê°œ ë¹ˆ í–‰ ì‚­ì œ")

        # ë¬¸ë‹¨ ì²˜ë¦¬ (í‘œ ê¸°ë°˜ í…œí”Œë¦¿ì—ì„œëŠ” ë¶ˆí•„ìš”í•˜ë¯€ë¡œ ë¹„í™œì„±í™”)
        # process_paragraphs(doc, data, header_map)

        # BytesIOë¡œ ì €ì¥
        output = io.BytesIO()
        doc.save(output)
        output.seek(0)

        state["output_docx"] = output
        print("  âœ“ Word ë¬¸ì„œ ìƒì„± ì™„ë£Œ")

    except Exception as e:
        print(f"  âœ— Word ìƒì„± ì‹¤íŒ¨: {e}")
        state["error"] = f"DOCX generation failed: {str(e)}"

    return state


# -------------------------------------------------------
# ê·¸ë˜í”„ êµ¬ì„±
# -------------------------------------------------------
def create_meeting_minutes_workflow() -> StateGraph:
    """íšŒì˜ë¡ ìƒì„± ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ ìƒì„±"""
    workflow = StateGraph(MeetingMinutesState)

    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("prepare", prepare_transcript)
    workflow.add_node("analyze", analyze_with_llm)
    workflow.add_node("format", format_data)
    workflow.add_node("generate", generate_docx)

    # ì—£ì§€ ì—°ê²°
    workflow.set_entry_point("prepare")
    workflow.add_edge("prepare", "analyze")
    workflow.add_edge("analyze", "format")
    workflow.add_edge("format", "generate")
    workflow.add_edge("generate", END)

    return workflow.compile()


# -------------------------------------------------------
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# -------------------------------------------------------
def generate_meeting_minutes_with_graph(
    transcript_data: List[Tuple[str, str]],
    speakers: List[str],
    file_info: Dict[str, Any],
    template_path: str,
    api_key: str,
    form_type: int = 4
) -> io.BytesIO:
    """
    LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•œ íšŒì˜ë¡ ìƒì„±

    Args:
        transcript_data: [(speaker, text), ...] í˜•ì‹ì˜ ë…¹ì·¨ë¡
        speakers: í™”ì ëª©ë¡
        file_info: íŒŒì¼ ë©”íƒ€ì •ë³´
        template_path: Word í…œí”Œë¦¿ ê²½ë¡œ
        api_key: OpenAI API í‚¤
        form_type: í…œí”Œë¦¿ íƒ€ì… (1~4)

    Returns:
        io.BytesIO: ìƒì„±ëœ Word ë¬¸ì„œ
    """
    print("=" * 60)
    print("ğŸš€ LangGraph ê¸°ë°˜ íšŒì˜ë¡ ìƒì„± ì›Œí¬í”Œë¡œìš° ì‹œì‘")
    print("=" * 60)

    # ì´ˆê¸° ìƒíƒœ ì„¤ì •
    initial_state: MeetingMinutesState = {
        "transcript_data": transcript_data,
        "speakers": speakers,
        "file_info": file_info,
        "template_path": template_path,
        "api_key": api_key,
        "form_type": form_type,
        "transcript_text": "",
        "analysis_result": {},
        "formatted_data": {},
        "output_docx": None,
        "error": ""
    }

    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    workflow = create_meeting_minutes_workflow()
    final_state = workflow.invoke(initial_state)

    print("=" * 60)
    print("âœ… ì›Œí¬í”Œë¡œìš° ì™„ë£Œ")
    print("=" * 60)

    # ì—ëŸ¬ ì²´í¬
    if final_state.get("error"):
        raise Exception(f"Workflow error: {final_state['error']}")

    return final_state["output_docx"]
