"""
íšŒì˜ íš¨ìœ¨ì„± ë¶„ì„ ì„œë¹„ìŠ¤ (ver1.ipynb í†µí•©)
"""
from typing import List, Dict, Any
from sqlalchemy.orm import Session
from app.models.audio_file import AudioFile
from app.models.transcript import FinalTranscript
from app.models.tagging import SpeakerMapping
from app.models.diarization import DiarizationResult
from app.models.stt import STTResult
from app.models.efficiency import MeetingEfficiencyAnalysis
from collections import defaultdict
import numpy as np
import logging

# íš¨ìœ¨ì„± ë¶„ì„ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import StandardScaler
import hdbscan
import torch
from transformers import GPT2LMHeadModel, GPT2TokenizerFast
from konlpy.tag import Mecab
import openai
import os

logger = logging.getLogger(__name__)

# ì „ì—­ ëª¨ë¸ (í•œ ë²ˆë§Œ ë¡œë“œ)
_embedding_model = None
_gpt2_model = None
_gpt2_tokenizer = None
_mecab = None

def get_embedding_model():
    """ì„ë² ë”© ëª¨ë¸ ì‹±ê¸€í†¤"""
    global _embedding_model
    if _embedding_model is None:
        try:
            logger.info("Loading sentence-transformers model...")
            print("[DEBUG] Loading embedding model...")
            _embedding_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
            logger.info("Model loaded successfully")
            print("[DEBUG] Embedding model loaded")
        except Exception as e:
            logger.error(f"Failed to load embedding model: {e}")
            print(f"[DEBUG] Failed to load embedding model: {e}")
            _embedding_model = None
    return _embedding_model


def get_gpt2_model():
    """GPT2 ëª¨ë¸ ì‹±ê¸€í†¤ (Perplexity ê³„ì‚°ìš©)"""
    global _gpt2_model, _gpt2_tokenizer
    if _gpt2_model is None:
        try:
            logger.info("Loading GPT2 model for PPL calculation...")
            _gpt2_tokenizer = GPT2TokenizerFast.from_pretrained("skt/kogpt2-base-v2")
            _gpt2_model = GPT2LMHeadModel.from_pretrained("skt/kogpt2-base-v2")
            _gpt2_model.eval()

            # GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ GPUë¡œ ì´ë™
            if torch.cuda.is_available():
                _gpt2_model = _gpt2_model.cuda()
                logger.info("GPT2 model loaded on GPU")
            else:
                logger.info("GPT2 model loaded on CPU")
        except Exception as e:
            logger.error(f"Failed to load GPT2 model: {e}")
            _gpt2_model = None
            _gpt2_tokenizer = None
    return _gpt2_model, _gpt2_tokenizer


def get_mecab():
    """Mecab í˜•íƒœì†Œ ë¶„ì„ê¸° ì‹±ê¸€í†¤ (TTR ê³„ì‚°ìš©)"""
    global _mecab
    if _mecab is None:
        try:
            logger.info("Loading Mecab morphological analyzer...")
            _mecab = Mecab()
            logger.info("Mecab loaded successfully")
        except Exception as e:
            logger.warning(f"Failed to load Mecab: {e}. Falling back to simple word splitting.")
            _mecab = None
    return _mecab


class EfficiencyAnalyzer:
    """
    ver1.ipynb ë¶„ì„ ì½”ë“œ í†µí•© ì„œë¹„ìŠ¤

    ì—­í• :
    - ver1.ipynbì˜ ê³„ì‚° ë¡œì§ë§Œ ì¶”ì¶œ (ì‹œê°í™” ì œê±°)
    - ê³„ì‚° ê²°ê³¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
    - DBì— MeetingEfficiencyAnalysis ê°ì²´ë¡œ ì €ì¥
    """

    def __init__(self, audio_file_id, db: Session):
        self.audio_file_id = audio_file_id
        self.db = db

        # í•„ìš” ë°ì´í„° ë¡œë“œ
        self.audio_file = self._load_audio_file()
        self.final_transcripts = self._load_transcripts()
        self.speaker_mappings = self._load_speaker_mappings()
        self.diarization_results = self._load_diarization()
        self.stt_results = self._load_stt()

    def _load_audio_file(self) -> AudioFile:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë³´ ë¡œë“œ - int ë˜ëŠ” str UUID ëª¨ë‘ ì§€ì›"""
        # Try by ID first (integer)
        audio_file = None
        try:
            audio_file_id_int = int(self.audio_file_id)
            audio_file = self.db.query(AudioFile).filter(
                AudioFile.id == audio_file_id_int
            ).first()
        except (ValueError, TypeError):
            pass

        # If not found or not an integer, try by file_path containing UUID
        if not audio_file:
            audio_file = self.db.query(AudioFile).filter(
                (AudioFile.file_path.like(f"%{self.audio_file_id}%")) |
                (AudioFile.original_filename.like(f"%{self.audio_file_id}%"))
            ).first()

        if not audio_file:
            raise ValueError(f"AudioFile {self.audio_file_id} not found")
        return audio_file

    def _load_transcripts(self) -> List[FinalTranscript]:
        """ìµœì¢… íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ë¡œë“œ"""
        return self.db.query(FinalTranscript).filter(
            FinalTranscript.audio_file_id == self.audio_file_id
        ).order_by(FinalTranscript.segment_index).all()

    def _load_speaker_mappings(self) -> List[SpeakerMapping]:
        """í™”ì ë§¤í•‘ ì •ë³´ ë¡œë“œ"""
        return self.db.query(SpeakerMapping).filter(
            SpeakerMapping.audio_file_id == self.audio_file_id
        ).all()

    def _load_diarization(self) -> List[DiarizationResult]:
        """í™”ì ë¶„ë¦¬ ê²°ê³¼ ë¡œë“œ"""
        return self.db.query(DiarizationResult).filter(
            DiarizationResult.audio_file_id == self.audio_file_id
        ).order_by(DiarizationResult.start_time).all()

    def _load_stt(self) -> List[STTResult]:
        """STT ê²°ê³¼ ë¡œë“œ"""
        return self.db.query(STTResult).filter(
            STTResult.audio_file_id == self.audio_file_id
        ).order_by(STTResult.word_index).all()

    def analyze_all(self) -> MeetingEfficiencyAnalysis:
        """
        ì „ì²´ ë¶„ì„ ì‹¤í–‰

        Returns:
            MeetingEfficiencyAnalysis: DB ì €ì¥ìš© ê°ì²´
        """
        logger.info(f"Starting efficiency analysis for audio_file_id={self.audio_file_id}")
        print(f"ğŸš€ [Efficiency] Starting analysis for file {self.audio_file_id}")
        print(f"[DEBUG] EfficiencyAnalyzer.analyze_all started for {self.audio_file_id}")

        # í™”ìë³„ ì§€í‘œ ê³„ì‚°
        speaker_metrics = []
        for speaker in self.speaker_mappings:
            logger.info(f"Analyzing speaker: {speaker.speaker_label}")
            print(f"[DEBUG] Analyzing speaker: {speaker.speaker_label}")

            metrics = {
                "speaker_label": speaker.speaker_label,
                "speaker_name": speaker.final_name or speaker.speaker_label,

                # ver1.ipynb ê° ì„¹ì…˜ì˜ ê³„ì‚° í•¨ìˆ˜ë“¤
                "turn_frequency": self._calc_turn_frequency(speaker),
                "ttr": self._calc_ttr(speaker),
                "information_content": self._calc_information_content(speaker),
                "sentence_probability": self._calc_sentence_probability(speaker),
                "perplexity": self._calc_perplexity(speaker)
            }
            speaker_metrics.append(metrics)

        # ì „ì²´ íšŒì˜ ì§€í‘œ ê³„ì‚°
        print("[DEBUG] Calculating overall metrics...")
        entropy_data = self._calc_entropy()
        overall_ttr = self._calc_overall_ttr()
        overall_info = self._calc_overall_information_content()
        overall_sent_prob = self._calc_overall_sentence_probability()
        overall_ppl = self._calc_overall_perplexity()

        # 8. Interaction Network
        interaction_network = self._calc_interaction_network()

        # 9. Qualitative Evaluation (LLM)
        qualitative_eval = self._generate_qualitative_evaluation(
            speaker_metrics=speaker_metrics,
            ttr=overall_ttr,
            info=overall_info,
            sent_prob=overall_sent_prob,
            ppl=overall_ppl
        )

        # DB ì €ì¥ ê°ì²´ ìƒì„±
        from datetime import datetime, timezone
        analysis = MeetingEfficiencyAnalysis(
            audio_file_id=self.audio_file.id,
            entropy_values=entropy_data["values"],
            entropy_avg=entropy_data["avg"],
            entropy_std=entropy_data["std"],
            speaker_metrics=speaker_metrics,
            overall_ttr=overall_ttr,
            overall_information_content=overall_info,
            overall_sentence_probability=overall_sent_prob,
            overall_perplexity=overall_ppl,
            
            # New metrics
            silence_analysis=self._calc_silence_analysis(),
            interaction_analysis=interaction_network,
            qualitative_analysis=qualitative_eval,

            total_speakers=len(self.speaker_mappings),
            total_turns=self._count_total_turns(),
            total_sentences=len(self.final_transcripts),
            analysis_version="1.0",
            analyzed_at=datetime.now(timezone.utc)
        )

        logger.info(f"Efficiency analysis completed for audio_file_id={self.audio_file_id}")
        print(f"âœ… [Efficiency] Analysis completed for file {self.audio_file_id}")
        return analysis

    def _count_total_turns(self) -> int:
        """ì „ì²´ í„´ ìˆ˜ ê³„ì‚°"""
        return len(self.diarization_results)

    # ========================================
    # ver1.ipynb ì½”ë“œ í†µí•©
    # ========================================

    def _calc_turn_frequency(self, speaker: SpeakerMapping) -> Dict[str, Any]:
        """
        ë°œí™” ë¹ˆë„ ê³„ì‚° (ver1.ipynb Cell 8: calculate_turn_taking)

        í™”ìë³„ ë°œí™” íšŸìˆ˜, ì´ ë°œí™” ì‹œê°„, í‰ê·  ë°œí™” ê¸¸ì´ ê³„ì‚°
        """
        # í™”ìë³„ diarization ê²°ê³¼ í•„í„°ë§
        speaker_diar = [d for d in self.diarization_results if d.speaker_label == speaker.speaker_label]

        if not speaker_diar:
            return {
                "turn_count": 0,
                "total_duration": 0.0,
                "avg_turn_length": 0.0,
                "time_series": []
            }

        # ë°œí™” íšŸìˆ˜
        turn_count = len(speaker_diar)

        # ì´ ë°œí™” ì‹œê°„
        total_duration = sum(d.end_time - d.start_time for d in speaker_diar)

        # í‰ê·  ë°œí™” ê¸¸ì´
        avg_turn_length = total_duration / turn_count if turn_count > 0 else 0.0

        # ì‹œê³„ì—´ ë°ì´í„° (ëˆ„ì  ë°œí™” íšŸìˆ˜)
        time_series = []
        cumulative_turns = 0
        for d in speaker_diar:
            cumulative_turns += 1
            time_series.append({
                "time": float(d.start_time),
                "cumulative_turns": cumulative_turns
            })

        return {
            "turn_count": turn_count,
            "total_duration": float(total_duration),
            "avg_turn_length": float(avg_turn_length),
            "time_series": time_series
        }

    def _calc_ttr(self, speaker: SpeakerMapping) -> Dict[str, Any]:
        """
        TTR ê³„ì‚° (ver1.ipynb Cell 18: load_ttr_data)

        Type-Token Ratio ê³„ì‚° (ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë°©ì‹)
        í˜•íƒœì†Œ ë¶„ì„ì´ í•„ìš”í•˜ë¯€ë¡œ í˜„ì¬ëŠ” ë‹¨ì–´ ê¸°ë°˜ìœ¼ë¡œ ë‹¨ìˆœí™”

        TODO: konlpy + mecabìœ¼ë¡œ í˜•íƒœì†Œ ë¶„ì„ ì¶”ê°€
        """
        # í™”ìë³„ ë°œí™” í…ìŠ¤íŠ¸ ì¶”ì¶œ
        speaker_transcripts = [
            t for t in self.final_transcripts
            if t.speaker_name == (speaker.final_name or speaker.speaker_label)
        ]

        if not speaker_transcripts:
            return {
                "ttr_values": [],
                "ttr_avg": 0.0,
                "ttr_std": 0.0
            }

        # ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•©
        texts = [t.text for t in speaker_transcripts]
        all_text = " ".join(texts)

        # Mecab í˜•íƒœì†Œ ë¶„ì„
        mecab = get_mecab()

        if mecab is not None:
            try:
                # í˜•íƒœì†Œ ë¶„ì„ ìˆ˜í–‰ (ëª…ì‚¬, ë™ì‚¬, í˜•ìš©ì‚¬ë§Œ ì¶”ì¶œ)
                morphs = mecab.pos(all_text)
                # ë‚´ìš©ì–´ë§Œ ì¶”ì¶œ (NNG, NNP, VV, VA ë“±)
                content_words = [
                    word for word, pos in morphs
                    if pos.startswith('NN') or pos.startswith('VV') or pos.startswith('VA')
                ]
                words = content_words
                logger.info(f"TTR: Mecab analysis - {len(words)} content words extracted")
            except Exception as e:
                logger.warning(f"Mecab analysis failed: {e}. Using word splitting.")
                words = all_text.split()
        else:
            # Fallback: ê³µë°± ê¸°ì¤€ ë¶„í• 
            words = all_text.split()
            logger.info(f"TTR: Using simple word splitting - {len(words)} words")

        if len(words) < 10:
            return {
                "ttr_values": [],
                "ttr_avg": 0.0,
                "ttr_std": 0.0
            }

        # ìŠ¬ë¼ì´ë”© ìœˆë„ìš° TTR ê³„ì‚°
        window_size = min(50, len(words) // 2)  # í˜•íƒœì†Œ ë‹¨ìœ„ ìœˆë„ìš°
        ttr_values = []

        for i in range(0, len(words) - window_size + 1, 10):  # 10í˜•íƒœì†Œì”© ì´ë™
            window_words = words[i:i + window_size]
            unique_words = len(set(window_words))
            total_words = len(window_words)
            ttr = unique_words / total_words if total_words > 0 else 0.0

            ttr_values.append({
                "window_start": i,
                "window_end": i + window_size,
                "ttr": float(ttr),
                "unique_words": unique_words,
                "total_words": total_words
            })

        # í‰ê·  ë° í‘œì¤€í¸ì°¨
        ttr_scores = [v["ttr"] for v in ttr_values]
        ttr_avg = float(np.mean(ttr_scores)) if ttr_scores else 0.0
        ttr_std = float(np.std(ttr_scores)) if ttr_scores else 0.0

        logger.info(f"TTR calculation completed: avg={ttr_avg:.3f}, std={ttr_std:.3f}")

        return {
            "ttr_values": ttr_values,
            "ttr_avg": ttr_avg,
            "ttr_std": ttr_std
        }

    def _calc_information_content(self, speaker: SpeakerMapping) -> Dict[str, Any]:
        """
        ì •ë³´ëŸ‰ ê³„ì‚° (ver1.ipynb Cell 23: load_information_data)

        ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ì •ë³´ëŸ‰ ì¸¡ì •
        - ì „ì²´ ë°œí™”ì˜ í‰ê·  ì„ë² ë”© vs ê° ë¬¸ì¥ ì„ë² ë”©
        - ë‚®ì€ ìœ ì‚¬ë„ = ë†’ì€ ì •ë³´ëŸ‰
        """
        # í™”ìë³„ ë°œí™” í…ìŠ¤íŠ¸ ì¶”ì¶œ
        speaker_transcripts = [
            t for t in self.final_transcripts
            if t.speaker_name == (speaker.final_name or speaker.speaker_label)
        ]

        if not speaker_transcripts or len(speaker_transcripts) < 2:
            return {
                "cosine_similarity_values": [],
                "avg_similarity": 0.0,
                "information_score": 0.0
            }

        try:
            # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
            model = get_embedding_model()

            # ë¬¸ì¥ ì„ë² ë”© ê³„ì‚°
            sentences = [t.text for t in speaker_transcripts]
            embeddings = model.encode(sentences, show_progress_bar=False)

            # ì „ì²´ ë°œí™”ì˜ í‰ê·  ì„ë² ë”© ê³„ì‚°
            mean_embedding = np.mean(embeddings, axis=0).reshape(1, -1)

            # ê° ë¬¸ì¥ê³¼ í‰ê·  ì„ë² ë”© ê°„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            similarities = cosine_similarity(embeddings, mean_embedding).flatten()

            # Z-ì •ê·œí™”
            scaler = StandardScaler()
            z_normalized = scaler.fit_transform(similarities.reshape(-1, 1)).flatten()

            # ê²°ê³¼ ì €ì¥
            cosine_similarity_values = []
            for i, t in enumerate(speaker_transcripts[:100]):  # ìµœëŒ€ 100ê°œ
                cosine_similarity_values.append({
                    "time": float(t.start_time),
                    "sentence": t.text[:100],
                    "similarity": float(similarities[i]),
                    "z_normalized": float(z_normalized[i])
                })

            avg_similarity = float(np.mean(similarities))
            information_score = 1.0 - avg_similarity  # ë‚®ì€ ìœ ì‚¬ë„ = ë†’ì€ ì •ë³´ëŸ‰

            return {
                "cosine_similarity_values": cosine_similarity_values,
                "avg_similarity": avg_similarity,
                "information_score": float(information_score)
            }
        except Exception as e:
            logger.error(f"Error calculating information content: {e}", exc_info=True)
            print(f"âŒ [Efficiency] Error calculating information content: {e}")
            return {
                "cosine_similarity_values": [],
                "avg_similarity": 0.0,
                "information_score": 0.0
            }

    def _calc_sentence_probability(self, speaker: SpeakerMapping) -> Dict[str, Any]:
        """
        ë¬¸ì¥ í™•ë¥  ê³„ì‚° (ver1.ipynb: HDBSCAN êµ°ì§‘í™”)

        ë¬¸ì¥ ì„ë² ë”© ê¸°ë°˜ êµ°ì§‘í™”ë¡œ í¬ê·€ ë¬¸ì¥ íƒì§€
        """
        # í™”ìë³„ ë°œí™” í…ìŠ¤íŠ¸ ì¶”ì¶œ
        speaker_transcripts = [
            t for t in self.final_transcripts
            if t.speaker_name == (speaker.final_name or speaker.speaker_label)
        ]

        if not speaker_transcripts or len(speaker_transcripts) < 5:
            return {
                "avg_probability": 0.0,
                "outlier_ratio": 0.0,
                "cluster_info": [],
                "rare_sentences": []
            }

        try:
            # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
            model = get_embedding_model()

            # ë¬¸ì¥ ì„ë² ë”© ê³„ì‚°
            sentences = [t.text for t in speaker_transcripts]
            embeddings = model.encode(sentences, show_progress_bar=False)

            # HDBSCAN êµ°ì§‘í™”
            clusterer = hdbscan.HDBSCAN(min_cluster_size=max(3, len(sentences) // 10))
            cluster_labels = clusterer.fit_predict(embeddings)

            # êµ°ì§‘ë³„ í†µê³„ ê³„ì‚°
            cluster_counts = defaultdict(int)
            for label in cluster_labels:
                cluster_counts[label] += 1

            total_sentences = len(speaker_transcripts)
            cluster_info = []
            for cluster_id, count in cluster_counts.items():
                if cluster_id != -1:  # -1ì€ ë…¸ì´ì¦ˆ
                    cluster_info.append({
                        "cluster_id": int(cluster_id),
                        "sentence_count": count,
                        "probability": round(count / total_sentences, 4)
                    })

            # í¬ê·€ ë¬¸ì¥ íƒì§€ (ë…¸ì´ì¦ˆ ë˜ëŠ” ì‘ì€ êµ°ì§‘)
            rare_sentences = []
            for i, (label, t) in enumerate(zip(cluster_labels, speaker_transcripts)):
                if label == -1 or cluster_counts[label] < 3:  # ë…¸ì´ì¦ˆ ë˜ëŠ” ì‘ì€ êµ°ì§‘
                    rare_sentences.append({
                        "sentence": t.text[:100],
                        "probability": round(cluster_counts[label] / total_sentences, 4) if label != -1 else 0.0,
                        "cluster_id": int(label)
                    })

            # í‰ê·  í™•ë¥  ë° ì´ìƒì¹˜ ë¹„ìœ¨ ê³„ì‚°
            outlier_count = sum(1 for label in cluster_labels if label == -1 or cluster_counts[label] < 3)
            outlier_ratio = outlier_count / total_sentences if total_sentences > 0 else 0.0

            # í‰ê·  í™•ë¥  (ì •ìƒ êµ°ì§‘ì˜ í‰ê·  í™•ë¥ )
            normal_probs = [count / total_sentences for label, count in cluster_counts.items() if label != -1 and count >= 3]
            avg_probability = np.mean(normal_probs) if normal_probs else 0.0

            return {
                "avg_probability": float(avg_probability),
                "outlier_ratio": float(outlier_ratio),
                "cluster_info": sorted(cluster_info, key=lambda x: x["probability"], reverse=True),
                "rare_sentences": rare_sentences[:10]  # ìµœëŒ€ 10ê°œ
            }
        except Exception as e:
            logger.error(f"Error calculating sentence probability: {e}", exc_info=True)
            print(f"âŒ [Efficiency] Error calculating sentence probability: {e}")
            return {
                "avg_probability": 0.0,
                "outlier_ratio": 0.0,
                "cluster_info": [],
                "rare_sentences": []
            }

    def _calc_perplexity(self, speaker: SpeakerMapping) -> Dict[str, Any]:
        """
        PPL ê³„ì‚° (ver1.ipynb Cell 36: calculate_conditional_ppl)

        GPT-2 ê¸°ë°˜ ì¡°ê±´ë¶€ Perplexity ê³„ì‚°
        """
        try:
            model, tokenizer = get_gpt2_model()
            if model is None or tokenizer is None:
                logger.warning("GPT2 model not available, skipping PPL calculation")
                return {
                    "ppl_values": [],
                    "ppl_avg": 0.0,
                    "ppl_std": 0.0
                }

            # í™”ì ë°œí™” ìˆ˜ì§‘
            speaker_transcripts = [
                t for t in self.final_transcripts
                if t.speaker_name == speaker.speaker_name
            ]

            if len(speaker_transcripts) < 3:  # ìµœì†Œ 3ê°œ ë¬¸ì¥ í•„ìš”
                return {
                    "ppl_values": [],
                    "ppl_avg": 0.0,
                    "ppl_std": 0.0
                }

            # ë°œí™” ìˆœì„œëŒ€ë¡œ ì •ë ¬
            sorted_transcripts = sorted(speaker_transcripts, key=lambda x: x.start_time)

            ppl_values = []
            device = 'cuda' if torch.cuda.is_available() else 'cpu'

            # ê° ë¬¸ì¥ì— ëŒ€í•´ ì´ì „ ë¬¸ì¥ë“¤ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•˜ì—¬ PPL ê³„ì‚°
            for i in range(1, len(sorted_transcripts)):
                # ì´ì „ ë¬¸ì¥ë“¤ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš© (ìµœëŒ€ 5ê°œ)
                context_start = max(0, i - 5)
                context_texts = [t.text for t in sorted_transcripts[context_start:i]]
                target_text = sorted_transcripts[i].text

                # ì»¨í…ìŠ¤íŠ¸ + íƒ€ê²Ÿ ê²°í•©
                full_text = " ".join(context_texts + [target_text])

                try:
                    # í† í¬ë‚˜ì´ì§•
                    encodings = tokenizer(full_text, return_tensors='pt', truncation=True, max_length=512)
                    input_ids = encodings['input_ids'].to(device)

                    # ëª¨ë¸ forward
                    with torch.no_grad():
                        outputs = model(input_ids, labels=input_ids)
                        loss = outputs.loss

                    # Perplexity = exp(loss)
                    ppl = torch.exp(loss).item()

                    # ì´ìƒì¹˜ ì œê±° (1000 ì´ìƒì€ ë„ˆë¬´ ë†’ìŒ)
                    if ppl < 1000:
                        ppl_values.append(ppl)

                except Exception as e:
                    logger.warning(f"Error calculating PPL for sentence {i}: {e}")
                    continue

            if not ppl_values:
                return {
                    "ppl_values": [],
                    "ppl_avg": 0.0,
                    "ppl_std": 0.0
                }

            ppl_avg = float(np.mean(ppl_values))
            ppl_std = float(np.std(ppl_values))

            return {
                "ppl_values": ppl_values[:50],  # ìµœëŒ€ 50ê°œë§Œ ì €ì¥
                "ppl_avg": ppl_avg,
                "ppl_std": ppl_std
            }

        except Exception as e:
            logger.error(f"Error calculating perplexity: {e}", exc_info=True)
            return {
                "ppl_values": [],
                "ppl_avg": 0.0,
                "ppl_std": 0.0
            }

    def _calc_entropy(self) -> Dict[str, Any]:
        """
        ì—”íŠ¸ë¡œí”¼ ê³„ì‚° (ver1.ipynb Cell 31: Entropy)

        TTR ê¸°ë°˜ ì „ì²´ ë‹´í™” ì—”íŠ¸ë¡œí”¼

        TODO: ì‹¤ì œ ì—”íŠ¸ë¡œí”¼ ê³„ì‚° êµ¬í˜„
        """
        if not self.final_transcripts:
            return {
                "values": [],
                "avg": 0.0,
                "std": 0.0
            }

        # ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•©
        all_text = " ".join([t.text for t in self.final_transcripts])
        words = all_text.split()

        if len(words) < 50:
            return {
                "values": [],
                "avg": 0.0,
                "std": 0.0
            }

        # ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì—”íŠ¸ë¡œí”¼ ê³„ì‚°
        window_size = 100  # ë‹¨ì–´ ë‹¨ìœ„
        entropy_values = []

        for i in range(0, len(words) - window_size + 1, 20):  # 20ë‹¨ì–´ì”© ì´ë™
            window_words = words[i:i + window_size]

            # ë‹¨ì–´ ë¹ˆë„ ê³„ì‚°
            word_freq = defaultdict(int)
            for word in window_words:
                word_freq[word] += 1

            # ì—”íŠ¸ë¡œí”¼ ê³„ì‚°: H = -Î£ p(x) * log2(p(x))
            total_words = len(window_words)
            entropy = 0.0
            for count in word_freq.values():
                p = count / total_words
                if p > 0:
                    entropy -= p * np.log2(p)

            time_offset = i / len(words) * self.audio_file.duration if self.audio_file.duration else i
            entropy_values.append({
                "time": float(time_offset),
                "entropy": float(entropy)
            })

        # í‰ê·  ë° í‘œì¤€í¸ì°¨
        entropy_scores = [v["entropy"] for v in entropy_values]
        entropy_avg = float(np.mean(entropy_scores)) if entropy_scores else 0.0
        entropy_std = float(np.std(entropy_scores)) if entropy_scores else 0.0

        return {
            "values": entropy_values[:100],  # ìµœëŒ€ 100ê°œë§Œ ì €ì¥
            "avg": entropy_avg,
            "std": entropy_std
        }

    # ========================================
    # ì „ì²´ íšŒì˜ ì§€í‘œ ê³„ì‚°
    # ========================================

    def _calc_overall_ttr(self) -> Dict[str, Any]:
        """ì „ì²´ íšŒì˜ TTR (Type-Token Ratio) ê³„ì‚°"""
        try:
            mecab = get_mecab()

            # ëª¨ë“  í™”ìì˜ í…ìŠ¤íŠ¸ ìˆ˜ì§‘
            all_texts = [t.text for t in self.final_transcripts if t.text]
            if not all_texts:
                return None

            combined_text = " ".join(all_texts)

            # í˜•íƒœì†Œ ë¶„ì„
            if mecab:
                morphs = mecab.morphs(combined_text)
            else:
                morphs = combined_text.split()

            if not morphs:
                return None

            # TTR ê³„ì‚°
            types = len(set(morphs))
            tokens = len(morphs)
            ttr = types / tokens if tokens > 0 else 0.0

            # ìœˆë„ìš° ê¸°ë°˜ TTR ê³„ì‚° (ì‹œê³„ì—´)
            window_size = 50
            ttr_values = []
            for i in range(0, len(morphs), window_size):
                window = morphs[i:i + window_size]
                if len(window) >= 10:
                    window_ttr = len(set(window)) / len(window)
                    ttr_values.append(window_ttr)

            return {
                "ttr_avg": float(ttr),
                "ttr_std": float(np.std(ttr_values)) if ttr_values else 0.0,
                "ttr_values": ttr_values[:100],  # ìµœëŒ€ 100ê°œ
                "total_types": types,
                "total_tokens": tokens
            }
        except Exception as e:
            logger.error(f"Error calculating overall TTR: {e}")
            return None

    def _calc_overall_information_content(self) -> Dict[str, Any]:
        """ì „ì²´ íšŒì˜ ì •ë³´ëŸ‰ (Information Content) ê³„ì‚°"""
        try:
            model = get_embedding_model()
            if model is None:
                return None

            # ëª¨ë“  ë¬¸ì¥ ì„ë² ë”©
            sentences = [t.text for t in self.final_transcripts if t.text]
            if len(sentences) < 2:
                return None

            embeddings = model.encode(sentences)

            # ì—°ì†ëœ ë¬¸ì¥ ê°„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„
            similarities = []
            for i in range(len(embeddings) - 1):
                sim = cosine_similarity([embeddings[i]], [embeddings[i + 1]])[0][0]
                similarities.append(float(sim))

            # ì •ë³´ ì ìˆ˜ = 1 - í‰ê·  ìœ ì‚¬ë„ (ë‚®ì€ ìœ ì‚¬ë„ = ë†’ì€ ì •ë³´ëŸ‰)
            avg_similarity = float(np.mean(similarities)) if similarities else 0.0
            information_score = 1.0 - avg_similarity

            return {
                "avg_similarity": avg_similarity,
                "information_score": information_score,
                "total_sentences": len(sentences)
            }
        except Exception as e:
            logger.error(f"Error calculating overall information content: {e}")
            return None

    def _calc_overall_sentence_probability(self) -> Dict[str, Any]:
        """ì „ì²´ íšŒì˜ ë¬¸ì¥ í™•ë¥  (Sentence Probability) ê³„ì‚°"""
        try:
            model = get_embedding_model()
            if model is None:
                return None

            # ëª¨ë“  ë¬¸ì¥ ì„ë² ë”©
            sentences = [t.text for t in self.final_transcripts if t.text]
            if len(sentences) < 5:  # ìµœì†Œ 5ê°œ ë¬¸ì¥ í•„ìš” (10ì—ì„œ 5ë¡œ ì™„í™”)
                return {
                    "avg_probability": 0.0,
                    "outlier_ratio": 1.0,
                    "total_sentences": len(sentences)
                }

            embeddings = model.encode(sentences)

            # HDBSCAN í´ëŸ¬ìŠ¤í„°ë§ìœ¼ë¡œ ì´ìƒì¹˜ íƒì§€
            clusterer = hdbscan.HDBSCAN(min_cluster_size=max(2, len(sentences) // 10))
            labels = clusterer.fit_predict(embeddings)

            # ì´ìƒì¹˜ (-1 ë ˆì´ë¸”) ë¹„ìœ¨
            outliers = sum(1 for label in labels if label == -1)
            outlier_ratio = outliers / len(labels) if len(labels) > 0 else 0.0

            # í‰ê·  í™•ë¥  (í´ëŸ¬ìŠ¤í„°ì— ì†í•œ ë¹„ìœ¨)
            avg_probability = 1.0 - outlier_ratio

            return {
                "avg_probability": float(avg_probability),
                "outlier_ratio": float(outlier_ratio),
                "total_sentences": len(sentences)
            }
        except Exception as e:
            logger.error(f"Error calculating overall sentence probability: {e}")
            return None

    def _calc_overall_perplexity(self) -> Dict[str, Any]:
        """ì „ì²´ íšŒì˜ Perplexity (PPL) ê³„ì‚°"""
        try:
            model, tokenizer = get_gpt2_model()
            if model is None or tokenizer is None:
                logger.warning("GPT2 model not available, skipping overall PPL calculation")
                return None

            # ëª¨ë“  ë¬¸ì¥ ìˆ˜ì§‘
            sentences = [t.text for t in self.final_transcripts if t.text]
            if len(sentences) < 5:  # ìµœì†Œ 5ê°œ ë¬¸ì¥ í•„ìš”
                return None

            # ë°œí™” ìˆœì„œëŒ€ë¡œ ì •ë ¬
            sorted_transcripts = sorted(self.final_transcripts, key=lambda x: x.start_time)

            ppl_values = []
            device = 'cuda' if torch.cuda.is_available() else 'cpu'

            # ê° ë¬¸ì¥ì— ëŒ€í•´ ì´ì „ ë¬¸ì¥ë“¤ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•˜ì—¬ PPL ê³„ì‚°
            for i in range(1, min(len(sorted_transcripts), 100)):  # ìµœëŒ€ 100ê°œ ë¬¸ì¥ë§Œ ê³„ì‚° (ë©”ëª¨ë¦¬ ì ˆì•½)
                # ì´ì „ ë¬¸ì¥ë“¤ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš© (ìµœëŒ€ 3ê°œ)
                context_start = max(0, i - 3)
                context_texts = [t.text for t in sorted_transcripts[context_start:i]]
                target_text = sorted_transcripts[i].text

                # ì»¨í…ìŠ¤íŠ¸ + íƒ€ê²Ÿ ê²°í•©
                full_text = " ".join(context_texts + [target_text])

                try:
                    # í† í¬ë‚˜ì´ì§•
                    encodings = tokenizer(full_text, return_tensors='pt', truncation=True, max_length=256)
                    input_ids = encodings['input_ids'].to(device)

                    # ëª¨ë¸ forward
                    with torch.no_grad():
                        outputs = model(input_ids, labels=input_ids)
                        loss = outputs.loss

                    # Perplexity = exp(loss)
                    ppl = torch.exp(loss).item()

                    # ì´ìƒì¹˜ ì œê±° (1000 ì´ìƒì€ ë„ˆë¬´ ë†’ìŒ)
                    if ppl < 1000:
                        ppl_values.append(ppl)

                except Exception as e:
                    logger.warning(f"Error calculating overall PPL for sentence {i}: {e}")
                    continue

            if not ppl_values:
                return None

            ppl_avg = float(np.mean(ppl_values))
            ppl_std = float(np.std(ppl_values))

            return {
                "ppl_avg": ppl_avg,
                "ppl_std": ppl_std,
                "sample_count": len(ppl_values)
            }

        except Exception as e:
            logger.error(f"Error calculating overall perplexity: {e}", exc_info=True)
            return None

    def _calc_silence_analysis(self) -> Dict[str, Any]:
        """
        ì¹¨ë¬µ ì‹œê°„ ë¶„ì„ (VER3.ipynb Logic)
        """
        try:
            segments = sorted(self.diarization_results, key=lambda x: x.start_time)
            gaps = []
            
            for i in range(len(segments) - 1):
                current_end = segments[i].end_time
                next_start = segments[i + 1].start_time
                gap_duration = next_start - current_end
                
                if gap_duration > 0.5: # 0.5ì´ˆ ì´ìƒë§Œ ì¹¨ë¬µìœ¼ë¡œ ê°„ì£¼
                    gaps.append({
                        "start_time": float(current_end),
                        "duration": float(gap_duration),
                        "prev_speaker": segments[i].speaker_label,
                        "next_speaker": segments[i+1].speaker_label
                    })
            
            if not gaps:
                return {
                    "stats": {"total_silence": 0, "mean_silence": 0, "count": 0},
                    "gaps": []
                }
                
            gap_durations = [g['duration'] for g in gaps]
            stats = {
                "total_silence": float(sum(gap_durations)),
                "mean_silence": float(np.mean(gap_durations)),
                "median_silence": float(np.median(gap_durations)),
                "max_silence": float(max(gap_durations)),
                "min_silence": float(min(gap_durations)),
                "std_silence": float(np.std(gap_durations)),
                "count": len(gaps)
            }
            
            return {
                "stats": stats,
                "gaps": gaps[:100] # Limit size
            }
        except Exception as e:
            logger.error(f"Error calculating silence analysis: {e}")
            return None

    def _calc_interaction_network(self) -> Dict[str, Any]:
        """
        í™”ì ê°„ ìƒí˜¸ì‘ìš© ë„¤íŠ¸ì›Œí¬ ë¶„ì„ (Interaction Graph)
        Nodes: í™”ì
        Edges: ë°œí™” ì „í™˜ (Turn-taking) ë¹ˆë„
        """
        try:
            if not self.final_transcripts:
                return None

            # 1. Nodes (Speakers)
            # FinalTranscript has speaker_name, not speaker_label
            # Get unique speakers
            speaker_names = list(set(t.speaker_name for t in self.final_transcripts if t.speaker_name))
            nodes = [{"id": name, "label": name} for name in speaker_names]

            # 2. Edges (Transitions)
            transitions = defaultdict(int)
            sorted_transcripts = sorted(self.final_transcripts, key=lambda x: x.start_time)

            for i in range(len(sorted_transcripts) - 1):
                current_speaker = sorted_transcripts[i].speaker_name
                next_speaker = sorted_transcripts[i+1].speaker_name

                if current_speaker != next_speaker:
                    transitions[(current_speaker, next_speaker)] += 1

            links = []
            for (source, target), count in transitions.items():
                links.append({
                    "source": source,
                    "target": target,
                    "value": count
                })

            return {
                "nodes": nodes,
                "links": links
            }

        except Exception as e:
            logger.error(f"Error calculating interaction network: {e}", exc_info=True)
            return None

    def _generate_qualitative_evaluation(self, speaker_metrics, ttr, info, sent_prob, ppl) -> str:
        """
        LLM ê¸°ë°˜ ì •ì„±ì  í‰ê°€ (VER2.ipynb Logic)
        """
        try:
            client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
            
            # Prepare data summary for LLM
            transcript_preview = " ".join([t.text for t in self.final_transcripts[:50]]) + "..." # First 50 segments
            
            metrics_summary = {
                "speakers": [s['speaker_name'] for s in speaker_metrics],
                "turn_counts": {s['speaker_name']: s['turn_frequency']['turn_count'] for s in speaker_metrics},
                "avg_ttr": ttr['ttr_avg'] if ttr else 0,
                "avg_info": info['information_score'] if info else 0,
                "avg_ppl": ppl['ppl_avg'] if ppl else 0
            }
            
            prompt = f"""
            ë‹¹ì‹ ì€ ê¸°ì—… ì»¨ì„¤íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ íšŒì˜ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ íšŒì˜ íš¨ìœ¨ì„±ì„ í‰ê°€í•´ì£¼ì„¸ìš”.
            
            [íšŒì˜ ê°œìš”]
            - í™”ì ìˆ˜: {len(metrics_summary['speakers'])}ëª…
            - í™”ì ëª©ë¡: {", ".join(metrics_summary['speakers'])}
            - ë°œí™” ë¹ˆë„: {metrics_summary['turn_counts']}
            - ì–´íœ˜ ë‹¤ì–‘ì„±(TTR): {metrics_summary['avg_ttr']:.3f} (ë†’ì„ìˆ˜ë¡ ë‹¤ì–‘)
            - ì •ë³´ ë°€ë„: {metrics_summary['avg_info']:.3f} (ë†’ì„ìˆ˜ë¡ ì •ë³´ëŸ‰ ë§ìŒ)
            - ëŒ€í™” ë‚œì´ë„(PPL): {metrics_summary['avg_ppl']:.2f} (ë‚®ì„ìˆ˜ë¡ í‰ì´)
            
            [íšŒì˜ ì´ˆë°˜ ë‚´ìš© (ì°¸ê³ ìš©)]
            {transcript_preview}
            
            [í‰ê°€ í•­ëª©]
            1. ëª©ì  ëª…í™•ì„±: íšŒì˜ ëª©ì ì´ ëšœë ·í•˜ê³  ê³µìœ ë˜ì—ˆëŠ”ê°€?
            2. ë¬¸ì œ í•´ê²° ì¤‘ì‹¬: ë…¼ì˜ê°€ ìƒì‚°ì ì¸ê°€?
            3. ì‹œê°„ íš¨ìœ¨ì„±: ë°€ë„ ìˆê²Œ ì§„í–‰ë˜ì—ˆëŠ”ê°€?
            4. ì°¸ì—¬ ê· í˜•ì„±: íŠ¹ì •ì¸ì˜ ë…ì  ì—†ì´ ê³ ë¥´ê²Œ ì°¸ì—¬í–ˆëŠ”ê°€?
            5. ê²°ë¡  ëª…í™•ì„±: ì‹¤í–‰ ê°€ëŠ¥í•œ ê²°ë¡ ì´ ë„ì¶œë˜ì—ˆëŠ”ê°€?
            
            ê° í•­ëª©ë³„ë¡œ ì ìˆ˜(10ì  ë§Œì )ì™€ ì§§ì€ í‰, ê·¸ë¦¬ê³  ê°œì„ ì ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
            ë§ˆì§€ë§‰ì— ì¢…í•© ì ìˆ˜ì™€ ì´í‰ì„ ìš”ì•½í•´ì£¼ì„¸ìš”.
            """
            
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ íšŒì˜ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=1500
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"Error generating qualitative evaluation: {e}")
            return "í‰ê°€ ìƒì„± ì‹¤íŒ¨"


