"""
íšŒì˜ë¡ ìë™ ìƒì„± ì„œë¹„ìŠ¤ (íšŒì˜ë¡ì…ë ¥.ipynb ë¡œì§ í†µí•©)
LangChain + GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ë…¹ì·¨ë¡ì—ì„œ íšŒì˜ë¡ ìë™ ìƒì„±
"""
import os
import io
import re
import xml.etree.ElementTree as ET
from xml.dom import minidom
from typing import Dict, List, Tuple, Any, Optional
from pydantic import BaseModel, Field

from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import PydanticOutputParser

from docx import Document
from docx.shared import Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH


# -------------------------------------------------------
# Pydantic ëª¨ë¸ ì •ì˜
# -------------------------------------------------------
class MeetingAnalysis(BaseModel):
    """LLMì´ ë°˜í™˜í•  íšŒì˜ë¡ ë°ì´í„° êµ¬ì¡°"""
    agenda: str = Field(description="íšŒì˜ ì•ˆê±´ (ëª…ì‚¬í˜•ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ)")
    summary: str = Field(description="ì „ì²´ ìš”ì•½ ë° íšŒì˜ ë‚´ìš© (ìƒì„¸í•œ ë³¸ë¬¸)")
    key_decisions: str = Field(description="ê²°ì • ì‚¬í•­ ë° íšŒì˜ ê²°ê³¼ (ì—†ìœ¼ë©´ 'ì—†ìŒ')")
    action_items: str = Field(description="í–¥í›„ ê³„íš, í•  ì¼, ì§„í–‰ ì¼ì •")
    issues: str = Field(description="ì œê¸°ëœ ì´ìŠˆ, ìš°ë ¤ ì‚¬í•­, ë¹„ê³ ")
    next_agenda: str = Field(description="ë‹¤ìŒ íšŒì˜ ì•ˆê±´ (ì—†ìœ¼ë©´ 'ì—†ìŒ')")
    keywords: str = Field(description="í•µì‹¬ í‚¤ì›Œë“œ (ì‰¼í‘œ êµ¬ë¶„)")
    date: str = Field(description="íšŒì˜ ë‚ ì§œ (YYYY-MM-DD)")


# -------------------------------------------------------
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# -------------------------------------------------------
def clean_header(text: str) -> str:
    """í—¤ë” ì •ê·œí™”: ê³µë°± ì œê±° ë° ì „ê° ê¸°í˜¸ ë³€í™˜"""
    if not text:
        return ""
    text = "".join(text.split())
    text = text.replace("ï¼š", ":")
    return text


def format_text_content(text: str) -> str:
    """
    í…ìŠ¤íŠ¸ í¬ë§·íŒ…: ë¦¬ìŠ¤íŠ¸ ê¸°í˜¸ì™€ ë§ˆì¹¨í‘œ ê¸°ì¤€ ì¤„ë°”ê¿ˆ ì¶”ê°€
    """
    if not text:
        return ""
    text = str(text).strip()

    formatted = text
    # ë¦¬ìŠ¤íŠ¸ ê¸°í˜¸ ê¸°ë°˜ ì¤„ë°”ê¿ˆ
    formatted = re.sub(r'(?<=\S)\s+-\s+', r'\n- ', formatted)
    formatted = re.sub(r'(?<=\S)\s+â€¢\s+', r'\nâ€¢ ', formatted)
    formatted = re.sub(r'(?<=\S)\s+(\d+\.)\s+', r'\n\1 ', formatted)

    # ê¸´ ì¤„ê¸€ ê°•ì œ ë¶„ë¦¬ (ë§ˆì¹¨í‘œ ê¸°ì¤€)
    # ì¤„ë°”ê¿ˆì´ 3ê°œ ë¯¸ë§Œì´ê³  í…ìŠ¤íŠ¸ê°€ 50ì ì´ìƒì´ë©´ ê°•ì œ ë¶„ë¦¬
    if formatted.count('\n') < 3 and len(formatted) > 50:
        # ë§ˆì¹¨í‘œ ë’¤ì— ê³µë°±ì´ ìˆë“  ì—†ë“ , ë‹¤ìŒì— í•œê¸€ì´ë‚˜ ì˜ì–´ ëŒ€ë¬¸ìê°€ ì˜¤ë©´ ì¤„ë°”ê¿ˆ
        formatted = re.sub(r'(?<=[ê°€-í£]{2})\.\s*(?=[ê°€-í£A-Z])', r'.\n', formatted)

    return formatted


def delete_paragraph(paragraph):
    """ë¬¸ë‹¨ì„ ë¬¸ì„œì—ì„œ ì™„ì „íˆ ì‚­ì œ"""
    p = paragraph._element
    p.getparent().remove(p)
    p._p = p._element = None


def fill_element(element, text: str, label_prefix: Optional[str] = None):
    """Cell ë˜ëŠ” Paragraphì— í…ìŠ¤íŠ¸ ì…ë ¥"""
    element.text = ""
    if not text:
        return

    is_cell = hasattr(element, 'paragraphs')

    if is_cell:
        p = element.paragraphs[0] if element.paragraphs else element.add_paragraph()
    else:
        p = element

    final_text = text
    if label_prefix:
        final_text = f"{label_prefix} : {text}"

    lines = final_text.split('\n')
    for i, line in enumerate(lines):
        clean_line = line.strip()
        if not clean_line:
            continue
        if i == 0:
            p.text = clean_line
        else:
            p.add_run('\n' + clean_line)

    p.alignment = WD_ALIGN_PARAGRAPH.LEFT
    if p.runs:
        for run in p.runs:
            run.font.size = Pt(10)


def extract_participants_from_text(stt_text: str) -> str:
    """ë…¹ì·¨ë¡ í…ìŠ¤íŠ¸ì—ì„œ í™”ì ì´ë¦„ ì¶”ì¶œ"""
    if not stt_text:
        return ""
    speakers = set()
    pattern = re.compile(r'^\s*([^\s:].*?)\s*:\s+')

    for line in stt_text.split('\n'):
        match = pattern.match(line)
        if match:
            s = match.group(1).strip()
            if len(s) < 20:
                speakers.add(s)

    return ", ".join(sorted(list(speakers))) if speakers else ""


# -------------------------------------------------------
# í…œí”Œë¦¿ ìë™ ê°ì§€
# -------------------------------------------------------
def detect_template_type(template_path: str) -> int:
    """
    Word í…œí”Œë¦¿ íŒŒì¼ ë¶„ì„í•˜ì—¬ íƒ€ì… ê°ì§€
    Type 1: ê¸°ë³¸í˜•
    Type 2: ì˜ê²¬ ì¤‘ì‹¬í˜•
    Type 3: ê²°ê³¼ ì¤‘ì‹¬í˜•
    Type 4: ìƒì„¸ ê´€ë¦¬í˜•
    """
    if not os.path.exists(template_path):
        print(f"âš ï¸ í…œí”Œë¦¿ íŒŒì¼ ì—†ìŒ, ê¸°ë³¸ê°’(Type 1) ì‚¬ìš©")
        return 1

    try:
        doc = Document(template_path)
        all_text = ""
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    all_text += cell.text.replace(" ", "")
        for p in doc.paragraphs:
            all_text += p.text.replace(" ", "")

        if "ì˜ê²¬ì‚¬í•­" in all_text:
            return 2
        if "ì§„í–‰ì¼ì •" in all_text or "ì´ìŠˆ/ë¹„ê³ " in all_text:
            return 4
        if "íšŒì˜ê²°ê³¼" in all_text:
            return 3
        return 1
    except Exception as e:
        print(f"âš ï¸ í…œí”Œë¦¿ ê°ì§€ ì‹¤íŒ¨: {e}")
        return 1


# -------------------------------------------------------
# LangChain í”„ë¡¬í”„íŠ¸ ìƒì„±
# -------------------------------------------------------
def get_prompt_template(form_type: int) -> str:
    """ì–‘ì‹ íƒ€ì…ì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë°˜í™˜"""
    base_instruction = """
ë‹¹ì‹ ì€ ì „ë¬¸ íšŒì˜ë¡ ì‘ì„± ë¹„ì„œì…ë‹ˆë‹¤.
ì œê³µëœ ë…¹ì·¨ë¡ì„ ë¶„ì„í•˜ì—¬ ìš”ì²­ëœ JSON í˜•ì‹ì— ë§ì¶° ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.
ë‚´ìš©ì´ ì—†ëŠ” í•­ëª©ì€ "ì—†ìŒ"ì´ë¼ê³  ëª…ì‹œí•˜ì„¸ìš”.

**ì¤‘ìš”: ëª¨ë“  í•­ëª©ì€ ë°˜ë“œì‹œ ê°œì¡°ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”!**
- summary, issues, key_decisions, action_items, next_agendaëŠ” ê° í•­ëª©ì„ "- "ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.
- ê° í•­ëª©ë§ˆë‹¤ ë°˜ë“œì‹œ ì¤„ë°”ê¿ˆ(\n)ì„ ë„£ì–´ì•¼ í•©ë‹ˆë‹¤.
- ê¸´ ë¬¸ì¥ì„ í•˜ë‚˜ë¡œ ì“°ì§€ ë§ê³ , í•­ëª©ë³„ë¡œ ë¶„ë¦¬í•˜ì„¸ìš”.

ì˜ˆì‹œ:
summary: "- ì²« ë²ˆì§¸ ë…¼ì˜ ì‚¬í•­ì…ë‹ˆë‹¤.\n- ë‘ ë²ˆì§¸ ë…¼ì˜ ì‚¬í•­ì…ë‹ˆë‹¤.\n- ì„¸ ë²ˆì§¸ ê²°ë¡ ì…ë‹ˆë‹¤."
issues: "- ì²« ë²ˆì§¸ ì´ìŠˆì…ë‹ˆë‹¤.\n- ë‘ ë²ˆì§¸ ìš°ë ¤ ì‚¬í•­ì…ë‹ˆë‹¤."
"""

    specific_instructions = {
        1: """
[ì¤‘ì  ì‚¬í•­ - í•œ ì¤„ ìš”ì•½í˜• (Type 1)]
- 'summary' í•­ëª©ì— íšŒì˜ì˜ ì „ì²´ íë¦„, ì£¼ìš” ë…¼ì˜ ì‚¬í•­, ê²°ë¡ ì„ ì‘ì„±í•˜ì„¸ìš”.
- ë°˜ë“œì‹œ ê° ë¬¸ì¥ì„ "- "ë¡œ ì‹œì‘í•˜ê³  ì¤„ë°”ê¿ˆ(\n)ìœ¼ë¡œ êµ¬ë¶„í•˜ì„¸ìš”.
- ìµœì†Œ 5ê°œ ì´ìƒì˜ í•­ëª©ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
""",
        2: """
[ì¤‘ì  ì‚¬í•­ - ì˜ê²¬ ì¤‘ì‹¬í˜• (Type 2)]
- 'summary': ê° ì‚¬ì‹¤ì„ "- "ë¡œ ì‹œì‘í•˜ì—¬ ì‘ì„±
- 'issues': ê° ì˜ê²¬ì„ "- "ë¡œ ì‹œì‘í•˜ì—¬ ì‘ì„±
- í•­ëª©ë§ˆë‹¤ ë°˜ë“œì‹œ ì¤„ë°”ê¿ˆ(\n) í¬í•¨
""",
        3: """
[ì¤‘ì  ì‚¬í•­ - ê²°ê³¼ ì¤‘ì‹¬í˜• (Type 3)]
- 'summary': ê° ë…¼ì˜ë¥¼ "- "ë¡œ ì‹œì‘í•˜ì—¬ ì‘ì„±
- 'key_decisions': ê° ê²°ì •ì„ "- "ë¡œ ì‹œì‘í•˜ì—¬ ì‘ì„±
- í•­ëª©ë§ˆë‹¤ ë°˜ë“œì‹œ ì¤„ë°”ê¿ˆ(\n) í¬í•¨
""",
        4: """
[ì¤‘ì  ì‚¬í•­ - ìƒì„¸ ê´€ë¦¬í˜• (Type 4)]
- summary: ê° ì•ˆê±´ë³„ ë‚´ìš©ì„ "- "ë¡œ ì‹œì‘í•˜ì—¬ ì‘ì„±, ì¤„ë°”ê¿ˆ(\n)ìœ¼ë¡œ êµ¬ë¶„
- issues: ê° ì´ìŠˆë¥¼ "- "ë¡œ ì‹œì‘í•˜ì—¬ ì‘ì„±, ì›ì¸ê³¼ ì˜í–¥ í¬í•¨
- key_decisions: ê° ê²°ì •ì„ "- "ë¡œ ì‹œì‘í•˜ì—¬ ì‘ì„±
- action_items: ê° í•­ëª©ì„ "- [ë‹´ë‹¹ì] í•  ì¼ (ê¸°í•œ)" í˜•ì‹ìœ¼ë¡œ ì‘ì„±
- ëª¨ë“  í•­ëª© ì‚¬ì´ì— ë°˜ë“œì‹œ ì¤„ë°”ê¿ˆ(\n) í¬í•¨
"""
    }

    return f"{base_instruction}\n{specific_instructions.get(form_type, specific_instructions[1])}\n" + \
           "[í˜•ì‹ ì§€ì¹¨]\n{format_instructions}\n\n[ë…¹ì·¨ë¡]\n{transcript}"


# -------------------------------------------------------
# LangChain íšŒì˜ë¡ ë¶„ì„
# -------------------------------------------------------
def analyze_transcript_with_langchain(
    api_key: str,
    transcript_text: str,
    form_type: int = 4
) -> Dict[str, Any]:
    """
    LangChain + GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ë…¹ì·¨ë¡ ë¶„ì„
    """
    try:
        llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0,
            openai_api_key=api_key
        )

        parser = PydanticOutputParser(pydantic_object=MeetingAnalysis)

        prompt = PromptTemplate(
            template=get_prompt_template(form_type),
            input_variables=["transcript"],
            partial_variables={"format_instructions": parser.get_format_instructions()}
        )

        chain = prompt | llm | parser

        # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (í† í° ì œí•œ ë°©ì§€)
        result_obj = chain.invoke({"transcript": transcript_text[:15000]})

        # Pydantic v2 í˜¸í™˜
        try:
            result_dict = result_obj.model_dump()
        except AttributeError:
            result_dict = result_obj.dict()

        return result_dict

    except Exception as e:
        print(f"âŒ LangChain ë¶„ì„ ì˜¤ë¥˜: {e}")
        return {
            "agenda": "ë¶„ì„ ì‹¤íŒ¨",
            "summary": "íšŒì˜ë¡ ìë™ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "key_decisions": "ì—†ìŒ",
            "action_items": "ì—†ìŒ",
            "issues": "ì—†ìŒ",
            "next_agenda": "ì—†ìŒ",
            "keywords": "",
            "date": ""
        }


# -------------------------------------------------------
# ì„œëª…ë¶€(ì°¸ì„ì ëª…ë‹¨) ì²˜ë¦¬
# -------------------------------------------------------
def process_signature_table(table, participants_str: str) -> bool:
    """í‘œê°€ ì„œëª…ë¶€ì¸ì§€ í™•ì¸í•˜ê³ , ë§ìœ¼ë©´ ì°¸ì„ì ëª…ë‹¨ ì‘ì„±"""
    if not table.rows:
        return False
    try:
        if not table.rows[0].cells:
            return False
        headers = [clean_header(c.text) for c in table.rows[0].cells]
    except:
        return False

    is_sig = False
    req = ["ì„œëª…", "Sign", "ì—°ë½ì²˜"]
    if any(k in headers for k in req) and ("ì„±ëª…" in headers or "ì´ë¦„" in headers or "ì°¸ì„ì" in headers):
        is_sig = True
    if not is_sig and "ì°¸ì„ì" in headers and "ì„±ëª…" in headers and "ì†Œì†" in headers:
        is_sig = True

    if is_sig:
        print("âœï¸ ì„œëª…ë¶€ ë°œê²¬! ëª…ë‹¨ ì‘ì„± ì¤‘...")
        name_idx = -1
        for i, h in enumerate(headers):
            if "ì„±ëª…" in h or "ì´ë¦„" in h:
                name_idx = i
                break
        if name_idx == -1:
            for i, h in enumerate(headers):
                if "ì°¸ì„ì" in h:
                    name_idx = i
                    break
        if name_idx == -1:
            return False

        people = [p.strip() for p in participants_str.split(',') if p.strip()]
        p_cursor = 0
        for r in range(1, len(table.rows)):
            row = table.rows[r]
            if len(row.cells) <= name_idx:
                continue
            if clean_header(row.cells[name_idx].text) in ["ì„±ëª…", "ì„œëª…", "ì†Œì†", "ì§ê¸‰", "ì°¸ì„ì", "ë¹„ê³ "]:
                continue

            if p_cursor < len(people):
                fill_element(row.cells[name_idx], people[p_cursor])
                p_cursor += 1
            else:
                row.cells[name_idx].text = ""
        return True
    return False


# -------------------------------------------------------
# ë¬¸ë‹¨ ì²˜ë¦¬
# -------------------------------------------------------
def process_paragraphs(doc, data: Dict[str, str], header_map: Dict[str, str]):
    """ì¼ë°˜ ë¬¸ë‹¨(ë³¸ë¬¸) ìŠ¤ìº” ë° ìˆ˜ì •"""
    print("ğŸ” ì¼ë°˜ ë¬¸ë‹¨(ë³¸ë¬¸) ìŠ¤ìº” ë° ìˆ˜ì • ì¤‘...")
    i = 0
    while i < len(doc.paragraphs):
        p = doc.paragraphs[i]
        text_raw = p.text.strip()
        if not text_raw:
            i += 1
            continue

        clean_txt = clean_header(text_raw)

        # 1. í˜¼í•©í˜• (ì œëª© : ë‚´ìš©)
        if ":" in text_raw:
            parts = text_raw.split(":", 1)
            key_part = clean_header(parts[0])
            found_key = None
            for h_key, d_key in header_map.items():
                if h_key == key_part:
                    found_key = d_key
                    break

            if found_key:
                content = data.get(found_key, "")
                label = parts[0].strip()
                fill_element(p, content, label_prefix=label)
                print(f"  [ë¬¸ë‹¨] '{label}' ìˆ˜ì • ì™„ë£Œ")
                i += 1
                continue

        # 2. ì œëª©í˜• (ì œëª© ë‹¤ìŒ ì¤„ì— ë‚´ìš©)
        found_key = None
        for h_key, d_key in header_map.items():
            if h_key == clean_txt:
                found_key = d_key
                break

        if found_key:
            content = format_text_content(data.get(found_key, ""))
            if i + 1 < len(doc.paragraphs):
                next_p = doc.paragraphs[i + 1]
                fill_element(next_p, content)
                print(f"  [ë¬¸ë‹¨] '{text_raw}' í•˜ë‹¨ ë‚´ìš© ì‘ì„± ì™„ë£Œ")

            # ì”ì—¬ í…ìŠ¤íŠ¸ ì‚­ì œ
            check_idx = i + 2
            while check_idx < len(doc.paragraphs):
                check_p = doc.paragraphs[check_idx]
                check_txt = clean_header(check_p.text)
                is_next_header = False
                for hk in header_map.keys():
                    if hk == check_txt:
                        is_next_header = True
                        break
                if is_next_header:
                    break
                delete_paragraph(check_p)
            i += 1
        i += 1


# -------------------------------------------------------
# ë©”ì¸ í•¨ìˆ˜: Word íšŒì˜ë¡ ìƒì„±
# -------------------------------------------------------
def create_meeting_minutes_docx(
    transcript_data: List[Tuple[str, str]],
    speakers: List[str],
    file_info: Dict[str, Any],
    template_path: str,
    api_key: str,
    form_type: int = 4
) -> io.BytesIO:
    """
    LangGraph ì›Œí¬í”Œë¡œìš° ê¸°ë°˜ íšŒì˜ë¡ ìë™ ìƒì„±
    ë³µì¡í•œ ìƒì„± ê³¼ì •ì„ êµ¬ì¡°í™”ëœ ê·¸ë˜í”„ë¡œ ê´€ë¦¬

    Args:
        transcript_data: [(speaker, text), ...] í˜•ì‹ì˜ ë…¹ì·¨ë¡
        speakers: í™”ì ëª©ë¡
        file_info: íŒŒì¼ ë©”íƒ€ì •ë³´ (filename, created_at)
        template_path: Word í…œí”Œë¦¿ íŒŒì¼ ê²½ë¡œ
        api_key: OpenAI API í‚¤
        form_type: í…œí”Œë¦¿ íƒ€ì… (1~4)

    Returns:
        io.BytesIO: ìƒì„±ëœ Word ë¬¸ì„œ
    """
    # LangGraph ì›Œí¬í”Œë¡œìš° ì‚¬ìš©
    from .meeting_minutes_graph import generate_meeting_minutes_with_graph

    return generate_meeting_minutes_with_graph(
        transcript_data=transcript_data,
        speakers=speakers,
        file_info=file_info,
        template_path=template_path,
        api_key=api_key,
        form_type=form_type
    )

# ê¸°ì¡´ ì½”ë“œëŠ” meeting_minutes_graph.pyë¡œ ì´ë™ë¨

def _legacy_create_meeting_minutes_docx(
    transcript_data: List[Tuple[str, str]],
    speakers: List[str],
    file_info: Dict[str, Any],
    template_path: str,
    api_key: str,
    form_type: int = 4
) -> io.BytesIO:
    """
    ë ˆê±°ì‹œ ë²„ì „ (LangGraph ì—†ì´)
    """
    print(f"ğŸš€ íšŒì˜ë¡ ìë™ ìƒì„± ì‹œì‘...")
    print(f"âœ… ì„ íƒëœ ì–‘ì‹ íƒ€ì…: Type {form_type}")

    # 2. ë…¹ì·¨ë¡ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    transcript_text = "\n".join([f"{spk}: {txt}" for spk, txt in transcript_data])

    # 3. LangChain ë¶„ì„ ì‹¤í–‰
    print("ğŸ”— LangChain ë¶„ì„ ì¤‘...")
    analysis_result = analyze_transcript_with_langchain(api_key, transcript_text, form_type)

    # 4. ë©”íƒ€ ì •ë³´ì™€ ë³‘í•©
    participants = ", ".join(speakers)
    data = {
        "DATE": analysis_result.get("date") or str(file_info.get("created_at", ""))[:10],
        "PARTICIPANTS": participants,
        "SUMMARY": analysis_result.get("summary", ""),
        "AGENDA": analysis_result.get("agenda", ""),
        "DECISIONS": analysis_result.get("key_decisions", ""),
        "ACTION_ITEMS": analysis_result.get("action_items", ""),
        "KEYWORDS": analysis_result.get("keywords", ""),
        "ISSUES": analysis_result.get("issues", ""),
        "NEXT_AGENDA": analysis_result.get("next_agenda", "")
    }

    # 5. Word í…œí”Œë¦¿ ë¡œë“œ
    print(f"ğŸ“‚ ì–‘ì‹ íŒŒì¼ ë¡œë“œ: {template_path}")
    doc = Document(template_path)

    # í—¤ë” ë§¤í•‘
    header_map = {
        "ì¼ì‹œ": "DATE", "ë‚ ì§œ": "DATE", "íšŒì˜ì¼ì": "DATE", "íšŒì˜ë‚ ì§œ": "DATE", "íšŒì˜ì¼ì‹œ": "DATE",
        "ì°¸ì„ì": "PARTICIPANTS", "íšŒì˜ì°¸ì„ì": "PARTICIPANTS",
        "íšŒì˜ì•ˆê±´": "AGENDA", "ì£¼ì œ": "AGENDA", "íšŒì˜ì£¼ì œ": "AGENDA", "ì•ˆê±´": "AGENDA",
        "ë‚´ìš©": "SUMMARY", "íšŒì˜ë‚´ìš©": "SUMMARY", "ì£¼ìš”ì•ˆê±´ë°ë‚´ìš©": "SUMMARY",
        "ê²°ê³¼": "DECISIONS", "ê²°ì •ì‚¬í•­": "DECISIONS", "íšŒì˜ê²°ê³¼": "DECISIONS",
        "ê³„íš": "ACTION_ITEMS", "í–¥í›„ê³„íš": "ACTION_ITEMS", "ì§„í–‰ì¼ì •": "ACTION_ITEMS",
        "ë¹„ê³ ": "KEYWORDS", "ì´ìŠˆ": "KEYWORDS", "ì˜ê²¬ì‚¬í•­": "ISSUES", "ì˜ê²¬": "ISSUES",
        "ë‹¤ìŒíšŒì˜": "NEXT_AGENDA"
    }

    column_map = {
        "íšŒì˜ë‚´ìš©": {"main": "SUMMARY", "ì´ìŠˆ": "ISSUES", "ë¹„ê³ ": "ISSUES"},
        "ê²°ì •ì‚¬í•­": {"main": "DECISIONS", "ì§„í–‰ì¼ì •": "ACTION_ITEMS", "ê³„íš": "ACTION_ITEMS"}
    }

    # 6. í‘œ(Table) ì²˜ë¦¬
    for table in doc.tables:
        if process_signature_table(table, data["PARTICIPANTS"]):
            continue

        rows = table.rows
        if not rows:
            continue
        first_header = clean_header(rows[0].cells[0].text)

        # ë©€í‹° ì»¬ëŸ¼ í‘œ (ì–‘ì‹ 4)
        is_multi_column = False
        target_col_map = None
        for key, mapping in column_map.items():
            if key in first_header:
                header_cells_txt = [clean_header(c.text) for c in rows[0].cells]
                has_sub_col = False
                for txt in header_cells_txt[1:]:
                    if "ë‚´ìš©" in txt or "Content" in txt:
                        has_sub_col = True
                    for sub_k in mapping.keys():
                        if sub_k != "main" and sub_k in txt:
                            has_sub_col = True
                if has_sub_col:
                    is_multi_column = True
                    target_col_map = mapping
                    break

        if is_multi_column and target_col_map:
            col_indices = {}
            for idx, cell in enumerate(rows[0].cells):
                txt = clean_header(cell.text)
                if "ë‚´ìš©" in txt and "íšŒì˜ë‚´ìš©" not in txt:
                    col_indices[target_col_map["main"]] = idx
                for k, v in target_col_map.items():
                    if k != "main" and k in txt:
                        col_indices[v] = idx

            main_data = format_text_content(data.get(target_col_map["main"], "")).split('\n')
            main_data = [l.strip() for l in main_data if l.strip()]

            side_key = None
            side_data = []
            for k in col_indices:
                if k != target_col_map["main"]:
                    side_key = k
                    side_data = format_text_content(data.get(k, "")).split('\n')
                    side_data = [l.strip() for l in side_data if l.strip()]
                    break

            max_len = max(len(main_data), len(side_data))
            for i in range(max_len):
                target_row_idx = i + 1
                if target_row_idx >= len(rows):
                    break
                row = rows[target_row_idx]

                main_col_idx = col_indices.get(target_col_map["main"])
                if main_col_idx is not None:
                    if i < len(main_data):
                        fill_element(row.cells[main_col_idx], main_data[i])
                    else:
                        row.cells[main_col_idx].text = ""

                if side_key:
                    side_col_idx = col_indices.get(side_key)
                    if side_col_idx is not None:
                        if i < len(side_data):
                            fill_element(row.cells[side_col_idx], side_data[i])
                        else:
                            row.cells[side_col_idx].text = ""
            print(f"  - [í‘œ] '{first_header}' (ë©€í‹° ì»¬ëŸ¼) ì‘ì„± ì™„ë£Œ")
            continue

        # ì¼ë°˜ í‘œ ì²˜ë¦¬
        r_idx = 0
        while r_idx < len(rows):
            row = rows[r_idx]
            if not row.cells:
                r_idx += 1
                continue

            cell_text_raw = row.cells[0].text.strip()
            header_text = clean_header(cell_text_raw)

            is_mixed = False
            found_key = None
            label_prefix = None

            if ":" in cell_text_raw:
                parts = cell_text_raw.split(":", 1)
                key_part = clean_header(parts[0])
                if len(key_part) < 15:
                    for h_key, d_key in header_map.items():
                        if h_key in key_part:
                            found_key = d_key
                            is_mixed = True
                            label_prefix = parts[0].strip()
                            break

            if not is_mixed:
                if len(header_text) > 20 or header_text.startswith("-") or header_text.startswith("1."):
                    r_idx += 1
                    continue
                for h_key, d_key in header_map.items():
                    if h_key in header_text:
                        found_key = d_key
                        break

            if found_key:
                raw_content = data.get(found_key, "")
                formatted_content = format_text_content(raw_content)
                content_lines = [l.strip() for l in formatted_content.split('\n') if l.strip()]

                target_cell = None

                if is_mixed:
                    target_cell = row.cells[0]
                elif len(row.cells) > 1:
                    right_text = clean_header(row.cells[1].text)
                    if right_text not in ["ë‹´ë‹¹ì", "ë¹„ê³ "] and "ë‚´ìš©" not in right_text:
                        target_cell = row.cells[1]

                if target_cell is None:
                    if r_idx + 1 < len(rows):
                        bottom_text = clean_header(rows[r_idx + 1].cells[0].text)
                        is_next_header = False
                        if len(bottom_text) < 20:
                            for k in header_map.keys():
                                if k in bottom_text:
                                    is_next_header = True
                                    break
                        if not is_next_header:
                            target_cell = rows[r_idx + 1].cells[0]
                    else:
                        new_row = table.add_row()
                        target_cell = new_row.cells[0]

                if target_cell:
                    fill_element(target_cell, "\n".join(content_lines), label_prefix)
                    print(f"  - [í‘œ] '{header_text}' ì‘ì„± ì™„ë£Œ")
            r_idx += 1

    # 7. ë¬¸ë‹¨ ì²˜ë¦¬
    process_paragraphs(doc, data, header_map)

    # 8. BytesIOë¡œ ì €ì¥
    output = io.BytesIO()
    doc.save(output)
    output.seek(0)

    print("âœ… íšŒì˜ë¡ ìƒì„± ì™„ë£Œ!")
    return output
