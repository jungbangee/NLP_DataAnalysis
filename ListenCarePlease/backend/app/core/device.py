"""
ë””ë°”ì´ìŠ¤ ê°ì§€ ë° ì„¤ì • ìœ í‹¸ë¦¬í‹°
Mac (MPS), GPU (CUDA), CPU ìë™ ê°ì§€
"""
import torch
import platform
from typing import Literal

DeviceType = Literal["cuda", "mps", "cpu"]


def get_device() -> DeviceType:
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ ìµœì ì˜ ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€

    ìš°ì„ ìˆœìœ„:
    1. CUDA (NVIDIA GPU)
    2. MPS (Apple Silicon)
    3. CPU (fallback)

    Returns:
        "cuda" | "mps" | "cpu"
    """
    if torch.cuda.is_available():
        return "cuda"
    elif torch.backends.mps.is_available():
        # Apple Silicon (M1/M2/M3)
        return "mps"
    else:
        return "cpu"


def get_device_info() -> dict:
    """
    í˜„ì¬ ë””ë°”ì´ìŠ¤ ì •ë³´ ë°˜í™˜

    Returns:
        ë””ë°”ì´ìŠ¤ ì •ë³´ ë”•ì…”ë„ˆë¦¬
    """
    device = get_device()
    info = {
        "device": device,
        "platform": platform.system(),
        "machine": platform.machine(),
        "torch_version": torch.__version__,
    }

    if device == "cuda":
        info.update({
            "cuda_version": torch.version.cuda,
            "gpu_name": torch.cuda.get_device_name(0),
            "gpu_count": torch.cuda.device_count(),
        })
    elif device == "mps":
        info.update({
            "mps_available": True,
            "recommendation": "Apple Silicon detected - using Metal Performance Shaders"
        })
    else:
        info.update({
            "warning": "No GPU detected - using CPU (slower performance)"
        })

    return info


def print_device_info():
    """ë””ë°”ì´ìŠ¤ ì •ë³´ ì¶œë ¥"""
    info = get_device_info()
    print("=" * 50)
    print("ğŸ–¥ï¸  Device Configuration")
    print("=" * 50)
    for key, value in info.items():
        print(f"{key:20s}: {value}")
    print("=" * 50)


# ì „ì—­ ë””ë°”ì´ìŠ¤ ì„¤ì •
DEVICE = get_device()
