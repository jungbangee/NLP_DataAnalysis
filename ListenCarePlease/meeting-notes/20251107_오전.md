# 📝 회의록

---

## 1. 회의 개요
- **회의 제목:** 발화자 자동 태깅 AI 모델 검증 결과 공유 및 학습 방향 논의  
- **회의 일시:** 2025년 11월 7일 (금) 오전 9:59 ~ 10:15 (16분간)

---

## 2. 참석자 명단
- 김민서 외 4인 

---

## 3. 주요 안건
1. STT 및 화자 분리 모델별 테스트 결과 공유 (Nemo, SpeechBrain, Assembly AI, senko 등)  
2. 노이즈 전처리 및 Whisper 결합 성능 개선 방안 논의  
3. 최종 모델 후보 확정 및 불필요 모델 제외 결정  
4. 향후 학습(파인튜닝) 방향 및 데이터 가공 계획 설정  

---

## 4. 회의 내용

### 🔹 모델별 테스트 결과 공유
- **NVIDIA Nemo:**  
  - 핵심 기술은 **MSDD(Multi-Scale Diarization Decoder)**.  
  - 짧은 발화에서도 화자를 안정적으로 식별.  
  - 학습량이 많아(15,000시간 이상) 추가 파인튜닝 효과는 제한적.  
  - **기술 완성도 높고 결과 안정적**.  

- **SpeechBrain:**  
  - 속도는 빠르나 노이즈에 매우 약함.  
  - 문장 단위 구분 오류와 화자 인식 불안정 발생.  
  - 실사용 적합도 낮아 **기각 의견 다수**.  

- **Assembly AI:**  
  - STT + 화자 분리 통합형 구조로 간단하고 빠름.  
  - 품질 양호(최대 5명 인식 가능).  
  - 유료 서비스이지만 30분당 224원으로 저비용.  
  - 직접 제어 범위 제한으로 **보조형 모델로 보류**.  

- **senko:**  
  - 개인 개발자가 Pyannote를 최적화한 모델.  
  - Segment 3.0 + CAM++ 임베딩 구조로 속도와 정확도 모두 우수.  
  - 언어 비의존적이나 녹음 품질과 마이크 환경에 민감.  
  - **Whisper 전처리와 결합 시 성능 향상 예상**.  

---

### 🔹 모델 선정 결과
- **제외:** Google Cloud STT, SpeechBrain  
- **유지:** **Nemo, Assembly AI, Senko**  
- **Whisper 전처리 기반 노이즈 제거를 최우선 과제로 설정**, 오늘 오후 테스트 예정.  

---

### 🔹 학습 및 데이터 가공 논의
- 단순 모델 호출이 아닌 **기본 가중치 기반 자체 학습(파인튜닝)** 검토 필요성 제기.  
- **발화자 식별(Speaker Identification)** 기능을 직접 학습형 구조로 전환 제안.  
- 데이터는 충분하나 **재가공 및 병합 과정 필수**.  
- 텍스트 기반 화자 태깅 + 음성 임베딩 병행 학습 구조 구상.  

---

### 🔹 당일 계획
- **오후:** Whisper 기반 노이즈 전처리 테스트 및 녹음 데이터 수집.  
- **기획서:** 확정된 모델 구조(Nemo, senko, Assembly AI 보류형) 반영 후 초안 작성.  
- **성능 평가:** 기존 회의 음성 파일을 활용한 모델 비교 테스트 진행.  

---

## 5. 채택사항과 유보사항
- **채택사항**
  - 최종 모델 후보: Nemo, senko, Assembly AI(보류형).  
  - Whisper 기반 전처리 도입 결정.  
  - 파인튜닝 중심 학습 구조 검토 및 데이터 재가공 계획 수립.  

- **유보사항**
  - 발화자 식별 모델 학습 방식 구체화 (가중치 업데이트 범위).  
  - Whisper 전처리 후 화자 분리 성능 정량 평가.  

---

## 6. 향후 일정
| 날짜 | 내용 |
|------|------|
| **11월 7일 (금) 오후** | Whisper 전처리 테스트 및 노이즈 환경 검증 |
| **11월 8일 (토)** | 모델별 비교 결과 정리 및 기획서 보완 |
| **11월 11일 (화)** | 멘토링 및 피드백 반영 |
| **11월 12~14일** | 파이프라인 통합 및 발표 준비 |

---
